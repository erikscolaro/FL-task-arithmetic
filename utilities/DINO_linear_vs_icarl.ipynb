{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94738e6",
   "metadata": {},
   "source": [
    "# DINO ViT-S/16 Feature Extraction on CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138e2903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adrientrahan/.cache/torch/hub/facebookresearch_dino_main\n",
      "100%|██████████| 169M/169M [00:16<00:00, 10.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10/1563 (0.6%) completed\n",
      "Batch 20/1563 (1.3%) completed\n",
      "Batch 30/1563 (1.9%) completed\n",
      "Batch 40/1563 (2.6%) completed\n",
      "Batch 50/1563 (3.2%) completed\n",
      "Batch 60/1563 (3.8%) completed\n",
      "Batch 70/1563 (4.5%) completed\n",
      "Batch 80/1563 (5.1%) completed\n",
      "Batch 90/1563 (5.8%) completed\n",
      "Batch 100/1563 (6.4%) completed\n",
      "Batch 110/1563 (7.0%) completed\n",
      "Batch 120/1563 (7.7%) completed\n",
      "Batch 130/1563 (8.3%) completed\n",
      "Batch 140/1563 (9.0%) completed\n",
      "Batch 150/1563 (9.6%) completed\n",
      "Batch 160/1563 (10.2%) completed\n",
      "Batch 170/1563 (10.9%) completed\n",
      "Batch 180/1563 (11.5%) completed\n",
      "Batch 190/1563 (12.2%) completed\n",
      "Batch 200/1563 (12.8%) completed\n",
      "Batch 210/1563 (13.4%) completed\n",
      "Batch 220/1563 (14.1%) completed\n",
      "Batch 230/1563 (14.7%) completed\n",
      "Batch 240/1563 (15.4%) completed\n",
      "Batch 250/1563 (16.0%) completed\n",
      "Batch 260/1563 (16.6%) completed\n",
      "Batch 270/1563 (17.3%) completed\n",
      "Batch 280/1563 (17.9%) completed\n",
      "Batch 290/1563 (18.6%) completed\n",
      "Batch 300/1563 (19.2%) completed\n",
      "Batch 310/1563 (19.8%) completed\n",
      "Batch 320/1563 (20.5%) completed\n",
      "Batch 330/1563 (21.1%) completed\n",
      "Batch 340/1563 (21.8%) completed\n",
      "Batch 350/1563 (22.4%) completed\n",
      "Batch 360/1563 (23.0%) completed\n",
      "Batch 370/1563 (23.7%) completed\n",
      "Batch 380/1563 (24.3%) completed\n",
      "Batch 390/1563 (25.0%) completed\n",
      "Batch 400/1563 (25.6%) completed\n",
      "Batch 410/1563 (26.2%) completed\n",
      "Batch 420/1563 (26.9%) completed\n",
      "Batch 430/1563 (27.5%) completed\n",
      "Batch 440/1563 (28.2%) completed\n",
      "Batch 450/1563 (28.8%) completed\n",
      "Batch 460/1563 (29.4%) completed\n",
      "Batch 470/1563 (30.1%) completed\n",
      "Batch 480/1563 (30.7%) completed\n",
      "Batch 490/1563 (31.3%) completed\n",
      "Batch 500/1563 (32.0%) completed\n",
      "Batch 510/1563 (32.6%) completed\n",
      "Batch 520/1563 (33.3%) completed\n",
      "Batch 530/1563 (33.9%) completed\n",
      "Batch 540/1563 (34.5%) completed\n",
      "Batch 550/1563 (35.2%) completed\n",
      "Batch 560/1563 (35.8%) completed\n",
      "Batch 570/1563 (36.5%) completed\n",
      "Batch 580/1563 (37.1%) completed\n",
      "Batch 590/1563 (37.7%) completed\n",
      "Batch 600/1563 (38.4%) completed\n",
      "Batch 610/1563 (39.0%) completed\n",
      "Batch 620/1563 (39.7%) completed\n",
      "Batch 630/1563 (40.3%) completed\n",
      "Batch 640/1563 (40.9%) completed\n",
      "Batch 650/1563 (41.6%) completed\n",
      "Batch 660/1563 (42.2%) completed\n",
      "Batch 670/1563 (42.9%) completed\n",
      "Batch 680/1563 (43.5%) completed\n",
      "Batch 690/1563 (44.1%) completed\n",
      "Batch 700/1563 (44.8%) completed\n",
      "Batch 710/1563 (45.4%) completed\n",
      "Batch 720/1563 (46.1%) completed\n",
      "Batch 730/1563 (46.7%) completed\n",
      "Batch 740/1563 (47.3%) completed\n",
      "Batch 750/1563 (48.0%) completed\n",
      "Batch 760/1563 (48.6%) completed\n",
      "Batch 770/1563 (49.3%) completed\n",
      "Batch 780/1563 (49.9%) completed\n",
      "Batch 790/1563 (50.5%) completed\n",
      "Batch 800/1563 (51.2%) completed\n",
      "Batch 810/1563 (51.8%) completed\n",
      "Batch 820/1563 (52.5%) completed\n",
      "Batch 830/1563 (53.1%) completed\n",
      "Batch 840/1563 (53.7%) completed\n",
      "Batch 850/1563 (54.4%) completed\n",
      "Batch 860/1563 (55.0%) completed\n",
      "Batch 870/1563 (55.7%) completed\n",
      "Batch 880/1563 (56.3%) completed\n",
      "Batch 890/1563 (56.9%) completed\n",
      "Batch 900/1563 (57.6%) completed\n",
      "Batch 910/1563 (58.2%) completed\n",
      "Batch 920/1563 (58.9%) completed\n",
      "Batch 930/1563 (59.5%) completed\n",
      "Batch 940/1563 (60.1%) completed\n",
      "Batch 950/1563 (60.8%) completed\n",
      "Batch 960/1563 (61.4%) completed\n",
      "Batch 970/1563 (62.1%) completed\n",
      "Batch 980/1563 (62.7%) completed\n",
      "Batch 990/1563 (63.3%) completed\n",
      "Batch 1000/1563 (64.0%) completed\n",
      "Batch 1010/1563 (64.6%) completed\n",
      "Batch 1020/1563 (65.3%) completed\n",
      "Batch 1030/1563 (65.9%) completed\n",
      "Batch 1040/1563 (66.5%) completed\n",
      "Batch 1050/1563 (67.2%) completed\n",
      "Batch 1060/1563 (67.8%) completed\n",
      "Batch 1070/1563 (68.5%) completed\n",
      "Batch 1080/1563 (69.1%) completed\n",
      "Batch 1090/1563 (69.7%) completed\n",
      "Batch 1100/1563 (70.4%) completed\n",
      "Batch 1110/1563 (71.0%) completed\n",
      "Batch 1120/1563 (71.7%) completed\n",
      "Batch 1130/1563 (72.3%) completed\n",
      "Batch 1140/1563 (72.9%) completed\n",
      "Batch 1150/1563 (73.6%) completed\n",
      "Batch 1160/1563 (74.2%) completed\n",
      "Batch 1170/1563 (74.9%) completed\n",
      "Batch 1180/1563 (75.5%) completed\n",
      "Batch 1190/1563 (76.1%) completed\n",
      "Batch 1200/1563 (76.8%) completed\n",
      "Batch 1210/1563 (77.4%) completed\n",
      "Batch 1220/1563 (78.1%) completed\n",
      "Batch 1230/1563 (78.7%) completed\n",
      "Batch 1240/1563 (79.3%) completed\n",
      "Batch 1250/1563 (80.0%) completed\n",
      "Batch 1260/1563 (80.6%) completed\n",
      "Batch 1270/1563 (81.3%) completed\n",
      "Batch 1280/1563 (81.9%) completed\n",
      "Batch 1290/1563 (82.5%) completed\n",
      "Batch 1300/1563 (83.2%) completed\n",
      "Batch 1310/1563 (83.8%) completed\n",
      "Batch 1320/1563 (84.5%) completed\n",
      "Batch 1330/1563 (85.1%) completed\n",
      "Batch 1340/1563 (85.7%) completed\n",
      "Batch 1350/1563 (86.4%) completed\n",
      "Batch 1360/1563 (87.0%) completed\n",
      "Batch 1370/1563 (87.7%) completed\n",
      "Batch 1380/1563 (88.3%) completed\n",
      "Batch 1390/1563 (88.9%) completed\n",
      "Batch 1400/1563 (89.6%) completed\n",
      "Batch 1410/1563 (90.2%) completed\n",
      "Batch 1420/1563 (90.9%) completed\n",
      "Batch 1430/1563 (91.5%) completed\n",
      "Batch 1440/1563 (92.1%) completed\n",
      "Batch 1450/1563 (92.8%) completed\n",
      "Batch 1460/1563 (93.4%) completed\n",
      "Batch 1470/1563 (94.0%) completed\n",
      "Batch 1480/1563 (94.7%) completed\n",
      "Batch 1490/1563 (95.3%) completed\n",
      "Batch 1500/1563 (96.0%) completed\n",
      "Batch 1510/1563 (96.6%) completed\n",
      "Batch 1520/1563 (97.2%) completed\n",
      "Batch 1530/1563 (97.9%) completed\n",
      "Batch 1540/1563 (98.5%) completed\n",
      "Batch 1550/1563 (99.2%) completed\n",
      "Batch 1560/1563 (99.8%) completed\n",
      "Batch 1563/1563 (100.0%) completed\n",
      "Batch 10/313 (3.2%) completed\n",
      "Batch 20/313 (6.4%) completed\n",
      "Batch 30/313 (9.6%) completed\n",
      "Batch 40/313 (12.8%) completed\n",
      "Batch 50/313 (16.0%) completed\n",
      "Batch 60/313 (19.2%) completed\n",
      "Batch 70/313 (22.4%) completed\n",
      "Batch 80/313 (25.6%) completed\n",
      "Batch 90/313 (28.8%) completed\n",
      "Batch 100/313 (31.9%) completed\n",
      "Batch 110/313 (35.1%) completed\n",
      "Batch 120/313 (38.3%) completed\n",
      "Batch 130/313 (41.5%) completed\n",
      "Batch 140/313 (44.7%) completed\n",
      "Batch 150/313 (47.9%) completed\n",
      "Batch 160/313 (51.1%) completed\n",
      "Batch 170/313 (54.3%) completed\n",
      "Batch 180/313 (57.5%) completed\n",
      "Batch 190/313 (60.7%) completed\n",
      "Batch 200/313 (63.9%) completed\n",
      "Batch 210/313 (67.1%) completed\n",
      "Batch 220/313 (70.3%) completed\n",
      "Batch 230/313 (73.5%) completed\n",
      "Batch 240/313 (76.7%) completed\n",
      "Batch 250/313 (79.9%) completed\n",
      "Batch 260/313 (83.1%) completed\n",
      "Batch 270/313 (86.3%) completed\n",
      "Batch 280/313 (89.5%) completed\n",
      "Batch 290/313 (92.7%) completed\n",
      "Batch 300/313 (95.8%) completed\n",
      "Batch 310/313 (99.0%) completed\n",
      "Batch 313/313 (100.0%) completed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import cast\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Load DINO ViT-S/16 pre-trained from torch.hub\n",
    "\n",
    "dino_model = cast(\n",
    "    nn.Module,\n",
    "    torch.hub.load(\"facebookresearch/dino:main\", \"dino_vits16\", pretrained=True),\n",
    ")\n",
    "dino_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dino_model.to(device=device)\n",
    "\n",
    "# Use the preprocess defined in the previous cell\n",
    "# Make sure the dataset uses the correct preprocess\n",
    "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "\n",
    "# Transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256), transforms.CenterCrop(224), # Required for DINO\n",
    "    # transforms.RandomHorizontalFlip(), # Optional augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100(root=\"./data\", train=True, download=True, transform=preprocess)\n",
    "test_dataset = CIFAR100(root=\"./data\", train=False, download=True, transform=preprocess)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Function to extract features from a dataloader\n",
    "def extract_features_and_labels(dataloader, model, device):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        total_batches = len(dataloader)\n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            # Get features from the backbone (without the classification head)\n",
    "            features = model(images)\n",
    "            all_features.append(features.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == total_batches:\n",
    "                print(\n",
    "                    f\"Batch {batch_idx + 1}/{total_batches} ({(batch_idx + 1) / total_batches:.1%}) completed\"\n",
    "                )\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels\n",
    "\n",
    "\n",
    "# Extract features and labels for train\n",
    "train_features, train_labels = extract_features_and_labels(\n",
    "    train_loader, dino_model, device\n",
    ")\n",
    "torch.save(\n",
    "    {\"features\": train_features, \"labels\": train_labels},\n",
    "    \"features/train_features.pt\",\n",
    ")\n",
    "\n",
    "# Extract features and labels for test\n",
    "test_features, test_labels = extract_features_and_labels(\n",
    "    test_loader, dino_model, device\n",
    ")\n",
    "torch.save(\n",
    "    {\"features\": test_features, \"labels\": test_labels}, \"features/test_features.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd754a",
   "metadata": {},
   "source": [
    "# Linear Classifier Training on DINO Features\n",
    "\n",
    "This section describes the process of training a linear classifier on top of precomputed DINO ViT-S/16 features extracted from the CIFAR-100 dataset. The classifier is trained using early stopping and evaluated on the test split to monitor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2851731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adrientrahan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e76cb4f07d4810af00ad95d2def3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d5da5fd1e44709a2dba8a44571fc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b41803a27ae4d3bbc090517f8d09d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a93c3d4c7f64861aa3056e64a9b3962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc434c03b3c64992a70b0f87c78ebe03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dca905e88b456eb530b98f3b9cc8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce16aaa32b084642bfd1af14912cfe2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08b45b0c60d42ea91879f61ff06b0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d980a115f94c2382dc5e03f4bb57e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bff8766ba948f6ae3deb9aea4af985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7695699018da4762be1950d685321158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d2140784f14153ab5516bcea88621d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4047d09487644e44b5999952ce07d7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8ccee4e43c4375bad70de02cab4dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232f5a469878449abc35440989462173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77621ede69ce408eab7069a4d97f215f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbae37b5c29400c986faaf593650d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3dd16d749c47eebbd3a1ce344c7c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e122d71ceb4c14b7ce24f1070d9189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4fcf71d5764e5b90adbb7ad1753f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888416950f25439d8536fa221bb72dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d72729f754945cba99bb4d166edfc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b2bb588a104eba93851bee4a52907f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c50f0de56134fae956b3fb390c9a3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a848006c0ded41a5abaf54d049d34c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813586a6e3234c4fb73632383d871f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27ce19167224ed4b2766f3403bfabd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192ec0f188fc4d8fa3046c4f21fa27f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5772e3b2ac841f38fafdd78700825f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03791fe43c04426905d5fd23372f95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0dbe64eeed463f8ef9b7c05e6d6fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca87be677f04e70bc1ab00c6224bba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a163d10a6ca147e99f7ed88919b143af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe39edbcdfcb4f47a8ce845fbce5d6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8bd612c6a74dd6af65cab2ffe53dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca343e0b16584563a75a430285b73d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1638eca0493426b8d46d375528380de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ac91ef3f6d4a4eb619a33dd047da44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19eb9672f12a4567b76a2c3f1bac04ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab1a14c95f14714940a9f920c1797d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7a4cc9d2b84c998f086f651b883c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4149a363fa7a4949a1614e8ae80b89d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9f967f34a141949f403ebadc504dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4e4cab4777419384695f239cdc2e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed317e1016c4616a859fd62e77a86ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6690faedb5314a8d95ed3919486a779f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aede46d4c5364c51b553ef03912d9050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368297ca49f64f6a9bb9300709c3a35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279d9adbbe1e4804b44319a9117ea929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028b6c62c1b940c7b9e373b991a16c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43cebca6ed74b55b868322083896d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffc3ba6359a40ac97c23e4e84de1156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de9e83bb4ef4b2d9f83ecdca8145300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ef389b40ad4098893f95b5f0f6c84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba38a5a6d28442e0a20372ce4b0e8780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfe7027943b40d19a2908c118889cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9616924c9d47bca9a275966ede4f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ee2d4b795f427e96244194436db26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facf8bc66f354a06b0a45d0436dd199f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4ecb014e804162b931adea3fddc723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11b89cf41c1439587353f9706534cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31 Training:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea88ab3db0e44fb5a14a9e7629feb362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31 Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_loader), desc\u001b[38;5;241m=\u001b[39meval_desc, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m test_progress:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m features, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m    140\u001b[0m             features, labels \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    141\u001b[0m             outputs \u001b[38;5;241m=\u001b[39m model(features)\n",
      "File \u001b[0;32m~/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:207\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:207\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from typing import Optional, cast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10000\n",
    "batch_size = 10000\n",
    "test_batch_size = 1000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Early stopping parameters\n",
    "best_acc = 0\n",
    "patience_counter = 0\n",
    "best_model_state = {}\n",
    "patience = 10\n",
    "\n",
    "dino_pretrained = cast(\n",
    "    nn.Module,\n",
    "    torch.hub.load(\"facebookresearch/dino:main\", \"dino_vits16\", pretrained=True),\n",
    ")\n",
    "\n",
    "\n",
    "class CustomDino(nn.Module):\n",
    "    def __init__(self, num_classes: int = 100, backbone: Optional[nn.Module] = None):\n",
    "        super().__init__()\n",
    "        if backbone is None:\n",
    "            # Carica DINO senza pretrained e rimuove la head\n",
    "            backbone = cast(\n",
    "                nn.Module,\n",
    "                torch.hub.load(\n",
    "                    \"facebookresearch/dino:main\", \"dino_vits16\", pretrained=False\n",
    "                ),\n",
    "            )\n",
    "        self.backbone: nn.Module = backbone\n",
    "        self.classifier = nn.Linear(\n",
    "            384, num_classes\n",
    "        )  # 384 = output CLS token DINO ViT-S/16\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        features = self.backbone(x)  # [batch, 384]\n",
    "        logits = self.classifier(features)  # [batch, num_classes]\n",
    "        return logits  # , features\n",
    "\n",
    "\n",
    "model = CustomDino(num_classes=100, backbone=dino_pretrained)\n",
    "\n",
    "# Example preprocessing for an input image\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        # in federated training, we should consider to use mean and std of the cifar100\n",
    "        # these are the parameters on which dino was trained\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load precomputed features and labels\n",
    "train_data = torch.load(\"features/train_features.pt\")\n",
    "test_data = torch.load(\"features/test_features.pt\")\n",
    "\n",
    "train_features, train_labels = train_data[\"features\"], train_data[\"labels\"]\n",
    "test_features, test_labels = test_data[\"features\"], test_data[\"labels\"]\n",
    "\n",
    "# Create TensorDatasets and DataLoaders from features\n",
    "train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n",
    "# Optimizer for the head\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Train only the linear head for fun startin from the features\n",
    "# -----------------------------------\n",
    "\n",
    "complete_model = model\n",
    "model = model.classifier\n",
    "model.to(device=device)\n",
    "best_model = model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Create a epoch-level progress bar and update it per-batch\n",
    "    epoch_desc = f\"Epoch {epoch+1} Training\"\n",
    "    with tqdm(total=len(train_loader), desc=epoch_desc, leave=True) as progress:\n",
    "        for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "            # Move tensors to device\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * features.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Update the progress bar with running metrics\n",
    "            batch_loss = running_loss / total if total > 0 else 0\n",
    "            batch_acc = correct / total if total > 0 else 0\n",
    "            progress.set_postfix(\n",
    "                {\"loss\": f\"{batch_loss:.4f}\", \"acc\": f\"{batch_acc:.4f}\"}\n",
    "            )\n",
    "            progress.update(1)\n",
    "\n",
    "    epoch_loss = running_loss / total if total > 0 else 0\n",
    "    epoch_acc = correct / total if total > 0 else 0\n",
    "\n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    # Create a per-epoch evaluation progress bar\n",
    "    eval_desc = f\"Epoch {epoch+1} Evaluation\"\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(test_loader), desc=eval_desc, leave=True) as test_progress:\n",
    "            for features, labels in test_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * features.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "                test_progress.update(1)\n",
    "\n",
    "            test_loss = test_loss / test_total if test_total > 0 else 0\n",
    "            test_acc = test_correct / test_total if test_total > 0 else 0\n",
    "\n",
    "            test_progress.set_postfix(\n",
    "                {\n",
    "                    \"loss\": f\"{test_loss / test_total if test_total > 0 else 0:.4f}\",\n",
    "                    \"acc\": f\"{test_acc:.4f}\",\n",
    "                }\n",
    "            )\n",
    "            test_progress.update(1)\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch == 0:\n",
    "        best_acc = test_acc\n",
    "        if patience == 0:\n",
    "            print(\"Default patience = 3\")\n",
    "            patience = 3\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "torch.save(best_model_state, \"./linear_classifier.pth\")\n",
    "\n",
    "print(\n",
    "    f\"Best model statistics:\\nAccuracy: {best_acc:.4f}\\nPatience reached: {patience_counter}\\nModel state dict keys: {list(best_model_state.keys())}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f49b79",
   "metadata": {},
   "source": [
    "# Class Centroid Computation and Exemplar Selection\n",
    "\n",
    "This cell computes normalized class centroids from DINO features by randomly selecting a fixed number of exemplars per class. The centroids are saved for use in downstream tasks such as nearest centroid classification or incremental learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e627208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Configuration\n",
    "num_exemplars = 100\n",
    "\n",
    "# Load precomputed features\n",
    "train_data = torch.load(\"features/train_features.pt\")\n",
    "train_features = train_data[\"features\"].cpu()\n",
    "train_labels = train_data[\"labels\"].cpu()\n",
    "\n",
    "# Compute normalized mean vector (centroid) for each class\n",
    "unique_classes = torch.unique(train_labels).tolist()\n",
    "centroids = {}\n",
    "rng = torch.Generator().manual_seed(42)\n",
    "\n",
    "for cls in unique_classes:\n",
    "    # Extract all features for this class\n",
    "    class_mask = train_labels == cls\n",
    "    class_features = train_features[class_mask]\n",
    "\n",
    "    # Select num_exemplars randomly\n",
    "    n = class_features.size(0)\n",
    "    k = min(num_exemplars, n)\n",
    "    indices = torch.randperm(n, generator=rng)[:k]\n",
    "    exemplars = class_features[indices]\n",
    "\n",
    "    # Compute normalized mean (centroid)\n",
    "    centroid = F.normalize(exemplars.mean(dim=0, keepdim=True), p=2, dim=1).squeeze(0)\n",
    "    centroids[cls] = centroid\n",
    "\n",
    "# Save to disk\n",
    "torch.save(\n",
    "    {\"class\": unique_classes, \"centroid\": centroids},\n",
    "    \"./features/class_centroids.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d6019d",
   "metadata": {},
   "source": [
    "## Nearest Centroid Classification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93063e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def nearest_neighbor(class_centroids, feature_vector):\n",
    "    \"\"\"\n",
    "    Find the nearest class by computing distances to all centroids.\n",
    "\n",
    "    Args:\n",
    "        class_centroids: dict {class_label: centroid_tensor[384]}\n",
    "        feature_vector: torch.Tensor of shape [384]\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: int\n",
    "    \"\"\"\n",
    "    min_distance = float(\"inf\")\n",
    "    predicted_class = None\n",
    "\n",
    "    for cls, centroid in class_centroids.items():\n",
    "        # Compute Euclidean distance\n",
    "        distance = torch.linalg.vector_norm(feature_vector - centroid).item()\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            predicted_class = cls\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07c34dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4a4569d9ef4584ab30bbccc7a37438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Nearest Centroid Evaluation:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor Accuracy: 60.48% (6048/10000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load test features\n",
    "test_data = torch.load(\"features/test_features.pt\")\n",
    "test_features = test_data[\"features\"].cpu()\n",
    "test_labels = test_data[\"labels\"].cpu()\n",
    "\n",
    "# Load class centroids\n",
    "centroids_data = torch.load(\"./features/class_centroids.pth\")\n",
    "centroids = centroids_data[\"centroid\"]\n",
    "centroid_labels = centroids_data[\"class\"]\n",
    "\n",
    "# Evaluate accuracy using nearest neighbor\n",
    "correct = 0\n",
    "total = test_features.size(0)\n",
    "\n",
    "for i in tqdm(range(total), desc=\"Nearest Centroid Evaluation\"):\n",
    "    pred_idx = nearest_neighbor(centroids, test_features[i])\n",
    "    pred = centroid_labels[pred_idx]\n",
    "    if pred == test_labels[i].item():\n",
    "        correct += 1\n",
    "\n",
    "accuracy = 100.0 * correct / total\n",
    "print(f\"Nearest Neighbor Accuracy: {accuracy:.2f}% ({correct}/{total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd231e27",
   "metadata": {},
   "source": [
    "# Convert the centroids in linear layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6721ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "classifier = torch.zeros(100, 384)\n",
    "\n",
    "for cls, centroid in centroids.items():\n",
    "    classifier[cls, :] = centroid\n",
    "\n",
    "\n",
    "layer = nn.Linear(384, 100)\n",
    "layer.weight = nn.Parameter(classifier)\n",
    "layer.bias = nn.Parameter(torch.zeros(100))\n",
    "\n",
    "torch.save(layer.state_dict(), \"./trained/nearest_centroid_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "439746a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea05c214f59d44c087c72dbc557a7cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Linear Layer Evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Layer Accuracy: 60.48% (6048/10000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load test features\n",
    "test_data = torch.load(\"features/test_features.pt\")\n",
    "test_features = test_data[\"features\"].cpu()\n",
    "test_labels = test_data[\"labels\"].cpu()\n",
    "\n",
    "# Load the linear classifier\n",
    "linear_layer = nn.Linear(384, 100)\n",
    "linear_layer.load_state_dict(torch.load(\"./trained/nearest_centroid_classifier.pth\"))\n",
    "linear_layer.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "linear_layer.to(device)\n",
    "\n",
    "# Evaluate accuracy using the linear layer\n",
    "correct = 0\n",
    "total = test_features.size(0)\n",
    "batch_size = 1000\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, total, batch_size), desc=\"Linear Layer Evaluation\"):\n",
    "        batch_features = test_features[i : i + batch_size].to(device)\n",
    "        batch_labels = test_labels[i : i + batch_size]\n",
    "\n",
    "        # Forward pass through linear layer\n",
    "        logits = linear_layer(batch_features)\n",
    "        predictions = logits.argmax(dim=1).cpu()\n",
    "\n",
    "        correct += (predictions == batch_labels).sum().item()\n",
    "\n",
    "accuracy = 100.0 * correct / total\n",
    "print(f\"Linear Layer Accuracy: {accuracy:.2f}% ({correct}/{total})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
