{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f75fb896",
      "metadata": {
        "id": "f75fb896"
      },
      "source": [
        "# DINO ViT-S/16 Feature Extraction on CIFAR-100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3f3844",
      "metadata": {
        "id": "6d3f3844"
      },
      "source": [
        "## Compute feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d37f65",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import cast\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d35446",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20d35446",
        "outputId": "2796415f-32cd-43ab-d831-cce3fff58f41"
      },
      "outputs": [],
      "source": [
        "# Load DINO ViT-S/16 pre-trained from torch.hub\n",
        "\n",
        "dino_model = cast(\n",
        "    nn.Module,\n",
        "    torch.hub.load(\"facebookresearch/dino:main\", \"dino_vits16\", pretrained=True),\n",
        ")\n",
        "dino_model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dino_model.to(device=device)\n",
        "\n",
        "# Make sure the dataset uses the correct preprocess\n",
        "preprocess = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        ### Normalization ImageNet\n",
        "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ### Normalization Cifar100\n",
        "        transforms.Normalize(\n",
        "            mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761]\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = CIFAR100(root=\"./data\", train=True, download=True, transform=preprocess)\n",
        "test_dataset = CIFAR100(root=\"./data\", train=False, download=True, transform=preprocess)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# Function to extract features from a dataloader\n",
        "def extract_features_and_labels(dataloader, model, device):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        total_batches = len(dataloader)\n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "            images = images.to(device)\n",
        "            # Get features from the backbone (without the classification head)\n",
        "            features = model(images)\n",
        "            all_features.append(features.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == total_batches:\n",
        "                print(\n",
        "                    f\"Batch {batch_idx + 1}/{total_batches} ({(batch_idx + 1) / total_batches:.1%}) completed\"\n",
        "                )\n",
        "    all_features = torch.cat(all_features, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "    return all_features, all_labels\n",
        "\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(\"features\", exist_ok=True)\n",
        "\n",
        "# Extract features and labels for train (only if file doesn't exist)\n",
        "if os.path.exists(\"features/train_features.pt\"):\n",
        "    print(\"Train features already exist. Skipping computation.\")\n",
        "else:\n",
        "    print(\"Computing train features...\")\n",
        "    train_features, train_labels = extract_features_and_labels(\n",
        "        train_loader, dino_model, device\n",
        "    )\n",
        "    torch.save(\n",
        "        {\"features\": train_features, \"labels\": train_labels},\n",
        "        \"features/train_features.pt\",\n",
        "    )\n",
        "    print(\"Train features saved.\")\n",
        "\n",
        "# Extract features and labels for test (only if file doesn't exist)\n",
        "if os.path.exists(\"features/test_features.pt\"):\n",
        "    print(\"Test features already exist. Skipping computation.\")\n",
        "else:\n",
        "    print(\"Computing test features...\")\n",
        "    test_features, test_labels = extract_features_and_labels(\n",
        "        test_loader, dino_model, device\n",
        "    )\n",
        "    torch.save(\n",
        "        {\"features\": test_features, \"labels\": test_labels}, \"features/test_features.pt\"\n",
        "    )\n",
        "    print(\"Test features saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d45689f",
      "metadata": {
        "id": "1d45689f"
      },
      "source": [
        "## Custom Dino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "951ce433",
      "metadata": {
        "id": "951ce433"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, cast\n",
        "from torch import nn\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class CustomDino(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 100,\n",
        "        backbone: Optional[nn.Module] = None,\n",
        "        frozen_head: nn.Module = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if backbone is None:\n",
        "            backbone = cast(\n",
        "                nn.Module,\n",
        "                torch.hub.load(\n",
        "                    \"facebookresearch/dino:main\", \"dino_vits16\", pretrained=True\n",
        "                ),\n",
        "            )\n",
        "        self.backbone: nn.Module = backbone\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Attach the head\n",
        "        if frozen_head is not None:\n",
        "            self.head = frozen_head\n",
        "        else:\n",
        "            self.head = nn.Linear(384, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        ### Normalize features so the Linear layer acts as Cosine Similarity\n",
        "        ###features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
        "\n",
        "        logits = self.head(features)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625bf265",
      "metadata": {
        "id": "625bf265"
      },
      "source": [
        "## Compute Centroids function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5144c52f",
      "metadata": {
        "id": "5144c52f"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def compute_centroid(class_features, num_exemplars=None, rng_seed=42):\n",
        "    \"\"\"\n",
        "    Compute centroid using random exemplar selection.\n",
        "    If num_exemplars is None, use all samples.\n",
        "\n",
        "    Steps (following iCaRL paper):\n",
        "    1. Normalize each feature vector (L2 norm)\n",
        "    2. Compute mean of normalized features\n",
        "    3. Normalize the resulting centroid\n",
        "    \"\"\"\n",
        "    n = class_features.size(0)\n",
        "\n",
        "    if num_exemplars is None or num_exemplars >= n:\n",
        "        # Use all samples\n",
        "        exemplars = class_features\n",
        "    else:\n",
        "        # Select num_exemplars randomly\n",
        "        rng = torch.Generator().manual_seed(rng_seed)\n",
        "        indices = torch.randperm(n, generator=rng)[:num_exemplars]\n",
        "        exemplars = class_features[indices]\n",
        "\n",
        "    # Step 1: Normalize each feature vector\n",
        "    exemplars_normalized = F.normalize(exemplars, p=2, dim=1)\n",
        "\n",
        "    # Step 2: Compute mean of normalized features\n",
        "    mean_features = exemplars_normalized.mean(dim=0)\n",
        "\n",
        "    # Step 3: Normalize the centroid\n",
        "    centroid = F.normalize(mean_features.unsqueeze(0), p=2, dim=1).squeeze(0)\n",
        "\n",
        "    return centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M7joLAmWNqtH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7joLAmWNqtH",
        "outputId": "b0b05384-be72-4f67-b780-f2a562085076"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaviderandino\u001b[0m (\u001b[33mdaviderandino-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pip install wandb --quiet\n",
        "import wandb\n",
        "\n",
        "# Opzionale: fai il login subito se non l'hai già fatto\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G_pkRqjMjl-3",
      "metadata": {
        "id": "G_pkRqjMjl-3"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "\n",
        "\n",
        "def save_checkpoint_to_wandb(\n",
        "    run: wandb.Run,\n",
        "    checkpoint: dict,\n",
        "    filename: str = \"model.pth\",\n",
        "    metadata: dict = None,\n",
        ") -> None:\n",
        "    \"\"\"Save a PyTorch model to WandB as an artifact.\"\"\"\n",
        "\n",
        "    # 1. Save model locally\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "    # 2. Create artifact\n",
        "    artifact_name = (\n",
        "        f\"{run.group}-checkpoints\"\n",
        "        if hasattr(run, \"group\") and run.group\n",
        "        else \"checkpoints\"\n",
        "    )\n",
        "    artifact = wandb.Artifact(name=artifact_name, type=\"model\", metadata=metadata or {})\n",
        "\n",
        "    artifact.add_file(filename)\n",
        "\n",
        "    # 3. Log artifact to the existing run\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    print(f\"Model saved to WandB as artifact '{artifact_name}'.\")\n",
        "\n",
        "\n",
        "def load_checkpoint_from_wandb(\n",
        "    run: wandb.Run, model: Module, filename: str = \"model.pth\", version: str = \"latest\"\n",
        ") -> tuple[dict, wandb.Artifact] | None:\n",
        "    \"\"\"Download the latest model artifact and load it into `model`.\"\"\"\n",
        "    try:\n",
        "        artifact_name = (\n",
        "            f\"{run.group}-checkpoints\"\n",
        "            if hasattr(run, \"group\") and run.group\n",
        "            else \"checkpoints\"\n",
        "        )\n",
        "        artifact = run.use_artifact(f\"{artifact_name}:{version}\", type=\"model\")\n",
        "        artifact_dir = artifact.download()\n",
        "        model_path = Path(artifact_dir) / filename\n",
        "        print(f\"Loading model from: {model_path}\")\n",
        "        checkpoint = torch.load(\n",
        "            model_path,\n",
        "            model.device if hasattr(model, \"device\") else None,\n",
        "            weights_only=False,\n",
        "        )\n",
        "        print(f\"Successfully loaded model from: {model_path}\")\n",
        "        return checkpoint, artifact\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(f\"Model checkpoint not found on WandB. {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_centroids_to_wandb(\n",
        "    centroids: torch.Tensor,\n",
        "    entity: str = \"aml-fl-project\",\n",
        "    project: str = \"fl-task-arithmetic\",\n",
        "    artifact_name: str = \"nearest_centroid_classifier\",\n",
        "    filename: str = \"nearest_centroid_classifier.pth\",\n",
        "    metadata: dict = None,\n",
        ") -> None:\n",
        "    \"\"\"Save centroids to WandB as nearest_centroid_classifier artifact (same as model.py).\"\"\"\n",
        "\n",
        "    # Create state dict with weight tensor (matching Linear layer format)\n",
        "    state_dict = {\n",
        "        \"weight\": centroids,  # Shape: (100, 384)\n",
        "        \"bias\": torch.zeros(centroids.size(0)),  # Shape: (100,)\n",
        "    }\n",
        "\n",
        "    torch.save(state_dict, filename)\n",
        "\n",
        "    # Use wandb.Api() to log artifact (same approach as model.py for consistency)\n",
        "    api = wandb.Api()\n",
        "    artifact = wandb.Artifact(\n",
        "        name=artifact_name,\n",
        "        type=\"model\",  # Using \"model\" type like the loading function expects\n",
        "        metadata=metadata or {},\n",
        "    )\n",
        "    artifact.add_file(filename)\n",
        "\n",
        "    # Log using current run if available, otherwise need explicit run context\n",
        "    if wandb.run is not None:\n",
        "        wandb.run.log_artifact(artifact)\n",
        "        print(f\"Centroids saved to WandB as artifact '{artifact_name}'.\")\n",
        "    else:\n",
        "        print(\"Warning: No active wandb run. Artifact not logged.\")\n",
        "        print(f\"Please log artifact manually or within a wandb.init() context.\")\n",
        "\n",
        "\n",
        "def load_centroids_from_wandb(\n",
        "    entity: str = \"aml-fl-project\",\n",
        "    project: str = \"fl-task-arithmetic\",\n",
        "    artifact_name: str = \"nearest_centroid_classifier\",\n",
        "    version: str = \"latest\",\n",
        ") -> torch.Tensor | None:\n",
        "    \"\"\"Download nearest_centroid_classifier artifact from WandB (same as model.py).\"\"\"\n",
        "    try:\n",
        "        api = wandb.Api()\n",
        "        artifact_path = f\"{entity}/{project}/{artifact_name}:{version}\"\n",
        "        print(f\"Loading centroids from W&B: {artifact_path}\")\n",
        "        artifact = api.artifact(artifact_path)\n",
        "        artifact_dir = artifact.download()\n",
        "\n",
        "        pth_files = list(Path(artifact_dir).glob(\"*.pth\"))\n",
        "        if not pth_files:\n",
        "            raise FileNotFoundError(f\"No .pth file found in artifact {artifact_path}\")\n",
        "\n",
        "        centroids_path = pth_files[0]\n",
        "        print(f\"Loading centroids from: {centroids_path}\")\n",
        "\n",
        "        # Load the state dict and extract weights as centroids\n",
        "        state_dict = torch.load(centroids_path, weights_only=False)\n",
        "        centroids = state_dict[\"weight\"]  # Extract weight tensor (100, 384)\n",
        "\n",
        "        print(f\"Successfully loaded centroids with shape: {centroids.shape}\")\n",
        "        return centroids\n",
        "    except Exception as e:\n",
        "        print(f\"Centroids not found on WandB: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c58db6f6",
      "metadata": {
        "id": "c58db6f6"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XAaT0M5ikM4D",
      "metadata": {
        "id": "XAaT0M5ikM4D"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "LR = 1e-4  # FIX: Changed from 10e-4 (0.001) to 1e-4 (0.0001)\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-4\n",
        "EPOCHS = 30\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PATIENCE = 5\n",
        "\n",
        "ENTITY = \"aml-fl-project\"\n",
        "PROJECT = \"fl-task-arithmetic\"\n",
        "GROUP = \"baseline_Test_TA_changes\"\n",
        "NAME = f\"centralized-dino-icarl-cifar100-lr{LR}-mom{MOMENTUM}-wd{WEIGHT_DECAY}\"\n",
        "RUN_ID = f\"Test-TA-help\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f7d5f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "c5f7d5f5",
        "outputId": "8f5d079a-23f1-4c79-8bed-c04ff577f68a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Centroids for initialization...\n",
            "Centroids calculated.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</strong> at: <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</a><br> View project at: <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251217_121621-run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251217_121753-run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005' target=\"_blank\">centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</a></strong> to <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "artifact membership 'baseline-Davide-collab-test-checkpoints:latest' not found in 'aml-fl-project/fl-task-arithmetic'\n",
            "Model checkpoint not found on WandB. artifact membership 'baseline-Davide-collab-test-checkpoints:latest' not found in 'aml-fl-project/fl-task-arithmetic'\n",
            "Starting from scratch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 782/782 [08:11<00:00,  1.59it/s, loss=1.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Results: Train Loss: 1.7899 | Test Loss: 1.0647 | Test Acc: 68.96%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "0 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.794]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Results: Train Loss: 0.7885 | Test Loss: 0.8146 | Test Acc: 75.53%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "1 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.764]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Results: Train Loss: 0.5058 | Test Loss: 0.7781 | Test Acc: 77.26%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "2 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.385]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Results: Train Loss: 0.3082 | Test Loss: 0.6239 | Test Acc: 81.12%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "3 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.234]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Results: Train Loss: 0.1650 | Test Loss: 0.5716 | Test Acc: 83.31%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "4 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 782/782 [08:11<00:00,  1.59it/s, loss=0.0493]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Results: Train Loss: 0.0756 | Test Loss: 0.5314 | Test Acc: 85.26%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "5 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.0167]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Results: Train Loss: 0.0296 | Test Loss: 0.5356 | Test Acc: 85.42%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "6 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 782/782 [08:11<00:00,  1.59it/s, loss=0.00712]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Results: Train Loss: 0.0142 | Test Loss: 0.5436 | Test Acc: 85.78%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "7 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10:  94%|█████████▍| 736/782 [07:42<00:28,  1.60it/s, loss=0.00573]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor, Resize, CenterCrop\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "\n",
        "\n",
        "# Standard CIFAR-100 Normalization\n",
        "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "\n",
        "# Transforms\n",
        "transform_train = Compose(\n",
        "    [\n",
        "        Resize(256),\n",
        "        CenterCrop(224),  # Required for DINO\n",
        "        # transforms.RandomHorizontalFlip(), # Optional augmentation\n",
        "        ToTensor(),\n",
        "        Normalize(*stats),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_test = Compose(\n",
        "    [\n",
        "        Resize(256),\n",
        "        CenterCrop(224),\n",
        "        ToTensor(),\n",
        "        Normalize(*stats),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 1. LOAD RAW IMAGES (Required for fine-tuning backbone)\n",
        "# We use the raw dataset, not the precomputed features, so we can backprop through the last layer.\n",
        "train_dataset = datasets.CIFAR100(\n",
        "    root=\"./data\", train=True, download=True, transform=transform_train\n",
        ")\n",
        "test_dataset = datasets.CIFAR100(\n",
        "    root=\"./data\", train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(\n",
        "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
        ")\n",
        "testloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "\n",
        "def get_or_compute_centroids(run: wandb.Run, device):\n",
        "    \"\"\"Try to load centroids from WandB, otherwise compute them.\"\"\"\n",
        "\n",
        "    # Try loading from WandB first (using same artifact as model.py)\n",
        "    centroids = load_centroids_from_wandb()\n",
        "    if centroids is not None:\n",
        "        print(\"Loaded centroids from WandB.\")\n",
        "        return centroids.to(device)\n",
        "\n",
        "    # Compute centroids if not found\n",
        "    print(\"Centroids not found on WandB. Computing...\")\n",
        "    train_data = torch.load(\"features/train_features.pt\")\n",
        "    saved_features, saved_labels = train_data[\"features\"], train_data[\"labels\"]\n",
        "\n",
        "    num_classes = 100\n",
        "    feature_dim = saved_features.shape[1]\n",
        "    centroids = torch.zeros((num_classes, feature_dim))\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        class_features = saved_features[saved_labels == c]\n",
        "        if len(class_features) > 0:\n",
        "            # Use all samples (num_exemplars=None) like DINO_linear\n",
        "            centroids[c] = compute_centroid(class_features, num_exemplars=None)\n",
        "\n",
        "    # Save to WandB for future use (using same artifact name as model.py)\n",
        "    save_centroids_to_wandb(\n",
        "        centroids,\n",
        "        metadata={\"num_classes\": num_classes, \"feature_dim\": feature_dim},\n",
        "    )\n",
        "\n",
        "    print(\"Centroids calculated and saved to WandB.\")\n",
        "    return centroids\n",
        "\n",
        "\n",
        "def train(lr, momentum, weight_decay, epochs):\n",
        "    best_accuracy = 0.0\n",
        "    patience_counter = 0\n",
        "    run = wandb.init(\n",
        "        entity=ENTITY,\n",
        "        project=PROJECT,\n",
        "        group=GROUP,\n",
        "        name=NAME,\n",
        "        id=RUN_ID,\n",
        "        resume=\"allow\",\n",
        "        mode=\"online\",\n",
        "    )\n",
        "\n",
        "    # Get or compute centroids\n",
        "    centroids = get_or_compute_centroids(run, DEVICE)\n",
        "\n",
        "    # Construct the fixed linear layer from centroids\n",
        "    LinearLayer = nn.Linear(384, 100)\n",
        "    with torch.no_grad():\n",
        "        LinearLayer.weight.copy_(centroids)\n",
        "        LinearLayer.bias.zero_()\n",
        "\n",
        "    # Freeze the classification layer\n",
        "    for param in LinearLayer.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Initialize model with the frozen centroid head\n",
        "    model = CustomDino(num_classes=100, frozen_head=LinearLayer).to(DEVICE)\n",
        "\n",
        "    # Load checkpoint (if any)\n",
        "    checkpoint = load_checkpoint_from_wandb(run, model, \"model.pth\")\n",
        "    start_epoch = 0\n",
        "    if checkpoint is not None:\n",
        "        checkpoint_dict, artifact = checkpoint\n",
        "        model.load_state_dict(checkpoint_dict[\"model\"])\n",
        "        start_epoch = artifact.metadata[\"epoch\"] + 1\n",
        "        print(f\"Resuming from epoch {start_epoch}\")\n",
        "    else:\n",
        "        print(\"Starting from scratch\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # NO CLASSIFIER IN OPTIM SINCE WE ARE NOT UPDATING IT\n",
        "    optimizer = optim.SGD(\n",
        "        list(model.backbone.parameters()),\n",
        "        lr=lr,\n",
        "        momentum=momentum,\n",
        "        weight_decay=weight_decay,\n",
        "    )\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        # --- TRAINING ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        pbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Model returns Logits (scores), not features\n",
        "            outputs = model(images)\n",
        "\n",
        "            # CrossEntropy expects (Logits, Class_Indices)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "        scheduler.step()\n",
        "        avg_train_loss = running_loss / len(trainloader)\n",
        "\n",
        "        # --- EVALUATION ---\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "                # 1. Forward Pass\n",
        "                # The Frozen Linear Layer calculates the similarity to centroids for us.\n",
        "                outputs = model(images)  # Shape: [Batch_Size, 100]\n",
        "\n",
        "                # 2. Loss\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                # 3. Accuracy\n",
        "                # The class with the highest score (dot product) is the nearest centroid.\n",
        "                # No need for manual torch.cdist calculation.\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        avg_test_loss = test_loss / len(testloader)\n",
        "        acc = 100.0 * correct / total\n",
        "        print(\n",
        "            f\"Epoch {epoch+1} Results: Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f} | Test Acc: {acc:.2f}%\"\n",
        "        )\n",
        "\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"train_loss\": avg_train_loss,\n",
        "                \"test_loss\": avg_test_loss,\n",
        "                \"test_accuracy\": acc,\n",
        "                \"best_accuracy\": best_accuracy,\n",
        "                \"learning_rate\": optimizer.param_groups[0][\"lr\"],\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Checkpointing\n",
        "        if acc > best_accuracy:\n",
        "            best_accuracy = acc\n",
        "            save_checkpoint_to_wandb(\n",
        "                run,\n",
        "                {\n",
        "                    \"model\": model.state_dict(),\n",
        "                },\n",
        "                \"model.pth\",\n",
        "                {\"task\": model, \"accuracy\": acc, \"epoch\": epoch},\n",
        "            )\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter > PATIENCE:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        print(epoch, \"Saved checkpoint model to WandB.\")\n",
        "\n",
        "\n",
        "train(\n",
        "    lr=LR,\n",
        "    momentum=MOMENTUM,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    epochs=EPOCHS,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_flower",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
