{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f75fb896",
      "metadata": {
        "id": "f75fb896"
      },
      "source": [
        "# DINO ViT-S/16 Feature Extraction on CIFAR-100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3f3844",
      "metadata": {
        "id": "6d3f3844"
      },
      "source": [
        "## Compute feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "20d35446",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20d35446",
        "outputId": "2796415f-32cd-43ab-d831-cce3fff58f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 450MB/s]\n",
            "100%|██████████| 169M/169M [00:03<00:00, 47.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 10/1563 (0.6%) completed\n",
            "Batch 20/1563 (1.3%) completed\n",
            "Batch 30/1563 (1.9%) completed\n",
            "Batch 40/1563 (2.6%) completed\n",
            "Batch 50/1563 (3.2%) completed\n",
            "Batch 60/1563 (3.8%) completed\n",
            "Batch 70/1563 (4.5%) completed\n",
            "Batch 80/1563 (5.1%) completed\n",
            "Batch 90/1563 (5.8%) completed\n",
            "Batch 100/1563 (6.4%) completed\n",
            "Batch 110/1563 (7.0%) completed\n",
            "Batch 120/1563 (7.7%) completed\n",
            "Batch 130/1563 (8.3%) completed\n",
            "Batch 140/1563 (9.0%) completed\n",
            "Batch 150/1563 (9.6%) completed\n",
            "Batch 160/1563 (10.2%) completed\n",
            "Batch 170/1563 (10.9%) completed\n",
            "Batch 180/1563 (11.5%) completed\n",
            "Batch 190/1563 (12.2%) completed\n",
            "Batch 200/1563 (12.8%) completed\n",
            "Batch 210/1563 (13.4%) completed\n",
            "Batch 220/1563 (14.1%) completed\n",
            "Batch 230/1563 (14.7%) completed\n",
            "Batch 240/1563 (15.4%) completed\n",
            "Batch 250/1563 (16.0%) completed\n",
            "Batch 260/1563 (16.6%) completed\n",
            "Batch 270/1563 (17.3%) completed\n",
            "Batch 280/1563 (17.9%) completed\n",
            "Batch 290/1563 (18.6%) completed\n",
            "Batch 300/1563 (19.2%) completed\n",
            "Batch 310/1563 (19.8%) completed\n",
            "Batch 320/1563 (20.5%) completed\n",
            "Batch 330/1563 (21.1%) completed\n",
            "Batch 340/1563 (21.8%) completed\n",
            "Batch 350/1563 (22.4%) completed\n",
            "Batch 360/1563 (23.0%) completed\n",
            "Batch 370/1563 (23.7%) completed\n",
            "Batch 380/1563 (24.3%) completed\n",
            "Batch 390/1563 (25.0%) completed\n",
            "Batch 400/1563 (25.6%) completed\n",
            "Batch 410/1563 (26.2%) completed\n",
            "Batch 420/1563 (26.9%) completed\n",
            "Batch 430/1563 (27.5%) completed\n",
            "Batch 440/1563 (28.2%) completed\n",
            "Batch 450/1563 (28.8%) completed\n",
            "Batch 460/1563 (29.4%) completed\n",
            "Batch 470/1563 (30.1%) completed\n",
            "Batch 480/1563 (30.7%) completed\n",
            "Batch 490/1563 (31.3%) completed\n",
            "Batch 500/1563 (32.0%) completed\n",
            "Batch 510/1563 (32.6%) completed\n",
            "Batch 520/1563 (33.3%) completed\n",
            "Batch 530/1563 (33.9%) completed\n",
            "Batch 540/1563 (34.5%) completed\n",
            "Batch 550/1563 (35.2%) completed\n",
            "Batch 560/1563 (35.8%) completed\n",
            "Batch 570/1563 (36.5%) completed\n",
            "Batch 580/1563 (37.1%) completed\n",
            "Batch 590/1563 (37.7%) completed\n",
            "Batch 600/1563 (38.4%) completed\n",
            "Batch 610/1563 (39.0%) completed\n",
            "Batch 620/1563 (39.7%) completed\n",
            "Batch 630/1563 (40.3%) completed\n",
            "Batch 640/1563 (40.9%) completed\n",
            "Batch 650/1563 (41.6%) completed\n",
            "Batch 660/1563 (42.2%) completed\n",
            "Batch 670/1563 (42.9%) completed\n",
            "Batch 680/1563 (43.5%) completed\n",
            "Batch 690/1563 (44.1%) completed\n",
            "Batch 700/1563 (44.8%) completed\n",
            "Batch 710/1563 (45.4%) completed\n",
            "Batch 720/1563 (46.1%) completed\n",
            "Batch 730/1563 (46.7%) completed\n",
            "Batch 740/1563 (47.3%) completed\n",
            "Batch 750/1563 (48.0%) completed\n",
            "Batch 760/1563 (48.6%) completed\n",
            "Batch 770/1563 (49.3%) completed\n",
            "Batch 780/1563 (49.9%) completed\n",
            "Batch 790/1563 (50.5%) completed\n",
            "Batch 800/1563 (51.2%) completed\n",
            "Batch 810/1563 (51.8%) completed\n",
            "Batch 820/1563 (52.5%) completed\n",
            "Batch 830/1563 (53.1%) completed\n",
            "Batch 840/1563 (53.7%) completed\n",
            "Batch 850/1563 (54.4%) completed\n",
            "Batch 860/1563 (55.0%) completed\n",
            "Batch 870/1563 (55.7%) completed\n",
            "Batch 880/1563 (56.3%) completed\n",
            "Batch 890/1563 (56.9%) completed\n",
            "Batch 900/1563 (57.6%) completed\n",
            "Batch 910/1563 (58.2%) completed\n",
            "Batch 920/1563 (58.9%) completed\n",
            "Batch 930/1563 (59.5%) completed\n",
            "Batch 940/1563 (60.1%) completed\n",
            "Batch 950/1563 (60.8%) completed\n",
            "Batch 960/1563 (61.4%) completed\n",
            "Batch 970/1563 (62.1%) completed\n",
            "Batch 980/1563 (62.7%) completed\n",
            "Batch 990/1563 (63.3%) completed\n",
            "Batch 1000/1563 (64.0%) completed\n",
            "Batch 1010/1563 (64.6%) completed\n",
            "Batch 1020/1563 (65.3%) completed\n",
            "Batch 1030/1563 (65.9%) completed\n",
            "Batch 1040/1563 (66.5%) completed\n",
            "Batch 1050/1563 (67.2%) completed\n",
            "Batch 1060/1563 (67.8%) completed\n",
            "Batch 1070/1563 (68.5%) completed\n",
            "Batch 1080/1563 (69.1%) completed\n",
            "Batch 1090/1563 (69.7%) completed\n",
            "Batch 1100/1563 (70.4%) completed\n",
            "Batch 1110/1563 (71.0%) completed\n",
            "Batch 1120/1563 (71.7%) completed\n",
            "Batch 1130/1563 (72.3%) completed\n",
            "Batch 1140/1563 (72.9%) completed\n",
            "Batch 1150/1563 (73.6%) completed\n",
            "Batch 1160/1563 (74.2%) completed\n",
            "Batch 1170/1563 (74.9%) completed\n",
            "Batch 1180/1563 (75.5%) completed\n",
            "Batch 1190/1563 (76.1%) completed\n",
            "Batch 1200/1563 (76.8%) completed\n",
            "Batch 1210/1563 (77.4%) completed\n",
            "Batch 1220/1563 (78.1%) completed\n",
            "Batch 1230/1563 (78.7%) completed\n",
            "Batch 1240/1563 (79.3%) completed\n",
            "Batch 1250/1563 (80.0%) completed\n",
            "Batch 1260/1563 (80.6%) completed\n",
            "Batch 1270/1563 (81.3%) completed\n",
            "Batch 1280/1563 (81.9%) completed\n",
            "Batch 1290/1563 (82.5%) completed\n",
            "Batch 1300/1563 (83.2%) completed\n",
            "Batch 1310/1563 (83.8%) completed\n",
            "Batch 1320/1563 (84.5%) completed\n",
            "Batch 1330/1563 (85.1%) completed\n",
            "Batch 1340/1563 (85.7%) completed\n",
            "Batch 1350/1563 (86.4%) completed\n",
            "Batch 1360/1563 (87.0%) completed\n",
            "Batch 1370/1563 (87.7%) completed\n",
            "Batch 1380/1563 (88.3%) completed\n",
            "Batch 1390/1563 (88.9%) completed\n",
            "Batch 1400/1563 (89.6%) completed\n",
            "Batch 1410/1563 (90.2%) completed\n",
            "Batch 1420/1563 (90.9%) completed\n",
            "Batch 1430/1563 (91.5%) completed\n",
            "Batch 1440/1563 (92.1%) completed\n",
            "Batch 1450/1563 (92.8%) completed\n",
            "Batch 1460/1563 (93.4%) completed\n",
            "Batch 1470/1563 (94.0%) completed\n",
            "Batch 1480/1563 (94.7%) completed\n",
            "Batch 1490/1563 (95.3%) completed\n",
            "Batch 1500/1563 (96.0%) completed\n",
            "Batch 1510/1563 (96.6%) completed\n",
            "Batch 1520/1563 (97.2%) completed\n",
            "Batch 1530/1563 (97.9%) completed\n",
            "Batch 1540/1563 (98.5%) completed\n",
            "Batch 1550/1563 (99.2%) completed\n",
            "Batch 1560/1563 (99.8%) completed\n",
            "Batch 1563/1563 (100.0%) completed\n",
            "Batch 10/313 (3.2%) completed\n",
            "Batch 20/313 (6.4%) completed\n",
            "Batch 30/313 (9.6%) completed\n",
            "Batch 40/313 (12.8%) completed\n",
            "Batch 50/313 (16.0%) completed\n",
            "Batch 60/313 (19.2%) completed\n",
            "Batch 70/313 (22.4%) completed\n",
            "Batch 80/313 (25.6%) completed\n",
            "Batch 90/313 (28.8%) completed\n",
            "Batch 100/313 (31.9%) completed\n",
            "Batch 110/313 (35.1%) completed\n",
            "Batch 120/313 (38.3%) completed\n",
            "Batch 130/313 (41.5%) completed\n",
            "Batch 140/313 (44.7%) completed\n",
            "Batch 150/313 (47.9%) completed\n",
            "Batch 160/313 (51.1%) completed\n",
            "Batch 170/313 (54.3%) completed\n",
            "Batch 180/313 (57.5%) completed\n",
            "Batch 190/313 (60.7%) completed\n",
            "Batch 200/313 (63.9%) completed\n",
            "Batch 210/313 (67.1%) completed\n",
            "Batch 220/313 (70.3%) completed\n",
            "Batch 230/313 (73.5%) completed\n",
            "Batch 240/313 (76.7%) completed\n",
            "Batch 250/313 (79.9%) completed\n",
            "Batch 260/313 (83.1%) completed\n",
            "Batch 270/313 (86.3%) completed\n",
            "Batch 280/313 (89.5%) completed\n",
            "Batch 290/313 (92.7%) completed\n",
            "Batch 300/313 (95.8%) completed\n",
            "Batch 310/313 (99.0%) completed\n",
            "Batch 313/313 (100.0%) completed\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import cast\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "import os\n",
        "\n",
        "# Load DINO ViT-S/16 pre-trained from torch.hub\n",
        "\n",
        "dino_model = cast(\n",
        "    nn.Module,\n",
        "    torch.hub.load(\"facebookresearch/dino:main\", \"dino_vits16\", pretrained=True),\n",
        ")\n",
        "dino_model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dino_model.to(device=device)\n",
        "\n",
        "# Use the preprocess defined in the previous cell\n",
        "# Make sure the dataset uses the correct preprocess\n",
        "preprocess = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        # in federated training, we should consider to use mean and std of the cifar100\n",
        "        # these are the parameters on which dino was trained\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = CIFAR100(root=\"./data\", train=True, download=True, transform=preprocess)\n",
        "test_dataset = CIFAR100(root=\"./data\", train=False, download=True, transform=preprocess)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# Function to extract features from a dataloader\n",
        "def extract_features_and_labels(dataloader, model, device):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        total_batches = len(dataloader)\n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "            images = images.to(device)\n",
        "            # Get features from the backbone (without the classification head)\n",
        "            features = model(images)\n",
        "            all_features.append(features.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == total_batches:\n",
        "                print(\n",
        "                    f\"Batch {batch_idx + 1}/{total_batches} ({(batch_idx + 1) / total_batches:.1%}) completed\"\n",
        "                )\n",
        "    all_features = torch.cat(all_features, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "    return all_features, all_labels\n",
        "\n",
        "\n",
        "#Create the directory if it doesn't exist\n",
        "os.makedirs(\"features\", exist_ok=True)\n",
        "\n",
        "# Extract features and labels for train\n",
        "train_features, train_labels = extract_features_and_labels(\n",
        "    train_loader, dino_model, device\n",
        ")\n",
        "torch.save(\n",
        "    {\"features\": train_features, \"labels\": train_labels},\n",
        "    \"features/train_features.pt\",\n",
        ")\n",
        "\n",
        "# Extract features and labels for test\n",
        "test_features, test_labels = extract_features_and_labels(\n",
        "    test_loader, dino_model, device\n",
        ")\n",
        "torch.save(\n",
        "    {\"features\": test_features, \"labels\": test_labels}, \"features/test_features.pt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d45689f",
      "metadata": {
        "id": "1d45689f"
      },
      "source": [
        "## Custom Dino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "951ce433",
      "metadata": {
        "id": "951ce433"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, cast\n",
        "from torch import nn\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "class CustomDino(nn.Module):\n",
        "    def __init__(self, num_classes: int = 100, backbone: Optional[nn.Module] = None, frozen_head: nn.Module = None):\n",
        "        super().__init__()\n",
        "        if backbone is None:\n",
        "            backbone = cast(\n",
        "                nn.Module,\n",
        "                torch.hub.load(\n",
        "                    \"facebookresearch/dino:main\", \"dino_vits16\", pretrained=True\n",
        "                ),\n",
        "            )\n",
        "        self.backbone: nn.Module = backbone\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Attach the head\n",
        "        if frozen_head is not None:\n",
        "            self.head = frozen_head\n",
        "        else:\n",
        "            self.head = nn.Linear(384, num_classes)\n",
        "\n",
        "        # Add a learnable or fixed scale factor (Temperature)\n",
        "        # 30.0 is a standard value for Cosine Classifiers (FaceNet, etc.)\n",
        "        self.scale = nn.Parameter(torch.tensor(30.0))\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        # CRITICAL FIX 1: Normalize features so the Linear layer acts as Cosine Similarity\n",
        "        features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
        "\n",
        "        logits = self.head(features)\n",
        "\n",
        "        # CRITICAL FIX 2: Apply Temperature Scaling\n",
        "        # This expands the range from [-1, 1] to [-30, 30], allowing Softmax to work\n",
        "        return logits * self.scale\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625bf265",
      "metadata": {
        "id": "625bf265"
      },
      "source": [
        "## Compute Centroids function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5144c52f",
      "metadata": {
        "id": "5144c52f"
      },
      "outputs": [],
      "source": [
        "def compute_centroid(features, m,feature_size,DEVICE):\n",
        "    features = features.to(DEVICE)\n",
        "    # Compute mean of the class\n",
        "    with torch.no_grad():\n",
        "        features = F.normalize(features, p=2, dim=1)\n",
        "        class_mean = torch.mean(features, dim=0)\n",
        "\n",
        "        # Herding Selection\n",
        "        exemplar_features = []\n",
        "\n",
        "        # We assume features are [N, D]\n",
        "        # We iterate m times to pick m samples\n",
        "        for k in range(m):\n",
        "            S = (\n",
        "                torch.sum(torch.stack(exemplar_features), dim=0)\n",
        "                if len(exemplar_features) > 0\n",
        "                else torch.zeros(feature_size).to(DEVICE)\n",
        "            )\n",
        "\n",
        "            # Objective: minimize || class_mean - (S + phi(x)) / k   ||\n",
        "            phi = features  # [N, D]\n",
        "            mu = class_mean  # [D]\n",
        "            # Distance for all candidates\n",
        "            dists = torch.norm(mu - ((S + phi) / k), dim=1)\n",
        "            # Pick best that isn't already chosen (simple way: set dist to inf)\n",
        "            # In strict implementation, we remove the index.\n",
        "            best_idx = torch.argmin(dists).item()\n",
        "            exemplar_features.append(features[best_idx])\n",
        "\n",
        "            # Mask this index so it's not picked again\n",
        "            features[best_idx] = features[best_idx] + 10000  # Hacky mask\n",
        "    return torch.mean(torch.stack(exemplar_features), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --quiet\n",
        "import wandb\n",
        "\n",
        "# Opzionale: fai il login subito se non l'hai già fatto\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7joLAmWNqtH",
        "outputId": "b0b05384-be72-4f67-b780-f2a562085076"
      },
      "id": "M7joLAmWNqtH",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaviderandino\u001b[0m (\u001b[33mdaviderandino-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "\n",
        "def save_checkpoint_to_wandb(\n",
        "    run: wandb.Run,\n",
        "    checkpoint: dict,\n",
        "    filename: str = \"model.pth\",\n",
        "    metadata: dict = None,\n",
        ") -> None:\n",
        "    \"\"\"Save a PyTorch model to WandB as an artifact.\"\"\"\n",
        "\n",
        "    # 1. Save model locally\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "    # 2. Create artifact\n",
        "    artifact_name = f\"{run.group}-checkpoints\" if hasattr(run, \"group\") and run.group else \"checkpoints\"\n",
        "    artifact = wandb.Artifact(\n",
        "        name=artifact_name,\n",
        "        type=\"model\",\n",
        "        metadata=metadata or {}\n",
        "    )\n",
        "\n",
        "    artifact.add_file(filename)\n",
        "\n",
        "    # 3. Log artifact to the existing run\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    print(f\"Model saved to WandB as artifact '{artifact_name}'.\")\n",
        "\n",
        "\n",
        "def load_checkpoint_from_wandb(\n",
        "    run: wandb.Run,\n",
        "    model: Module,\n",
        "    filename: str = \"model.pth\",\n",
        "    version: str = \"latest\"\n",
        ") -> tuple[dict, wandb.Artifact] | None:\n",
        "    \"\"\"Download the latest model artifact and load it into `model`.\"\"\"\n",
        "    try:\n",
        "        artifact_name = f\"{run.group}-checkpoints\" if hasattr(run, \"group\") and run.group else \"checkpoints\"\n",
        "        artifact = run.use_artifact(f\"{artifact_name}:{version}\", type=\"model\")\n",
        "        artifact_dir = artifact.download()\n",
        "        model_path = Path(artifact_dir) / filename\n",
        "        print(f\"Loading model from: {model_path}\")\n",
        "        checkpoint = torch.load(model_path, model.device if hasattr(model, 'device') else None, weights_only=False)\n",
        "        print(f\"Successfully loaded model from: {model_path}\")\n",
        "        return checkpoint, artifact\n",
        "    except Exception as e :\n",
        "        print(e)\n",
        "        print(f\"Model checkpoint not found on WandB. {e}\")\n"
      ],
      "metadata": {
        "id": "G_pkRqjMjl-3"
      },
      "id": "G_pkRqjMjl-3",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c58db6f6",
      "metadata": {
        "id": "c58db6f6"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ENTITY = \"aml-fl-project\"\n",
        "PROJECT = \"fl-task-arithmetic\"\n",
        "GROUP = \"baseline-Davide-collab-test\"\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "LR  = 10e-4          # Learning Rate (Tune this: 0.1, 0.01, 0.001)\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-4\n",
        "EPOCHS = 10\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PATIENCE = 3"
      ],
      "metadata": {
        "id": "XAaT0M5ikM4D"
      },
      "id": "XAaT0M5ikM4D",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f7d5f5",
      "metadata": {
        "id": "c5f7d5f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "8f5d079a-23f1-4c79-8bed-c04ff577f68a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Centroids for initialization...\n",
            "Centroids calculated.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</strong> at: <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</a><br> View project at: <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251217_121621-run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251217_121753-run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005' target=\"_blank\">centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</a></strong> to <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-222-centralized-dino-icarl-cifar100-lr0.001-mom0.9-wd0.0005</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artifact membership 'baseline-Davide-collab-test-checkpoints:latest' not found in 'aml-fl-project/fl-task-arithmetic'\n",
            "Model checkpoint not found on WandB. artifact membership 'baseline-Davide-collab-test-checkpoints:latest' not found in 'aml-fl-project/fl-task-arithmetic'\n",
            "Starting from scratch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 782/782 [08:11<00:00,  1.59it/s, loss=1.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Results: Train Loss: 1.7899 | Test Loss: 1.0647 | Test Acc: 68.96%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "0 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.794]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Results: Train Loss: 0.7885 | Test Loss: 0.8146 | Test Acc: 75.53%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "1 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.764]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Results: Train Loss: 0.5058 | Test Loss: 0.7781 | Test Acc: 77.26%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "2 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.385]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Results: Train Loss: 0.3082 | Test Loss: 0.6239 | Test Acc: 81.12%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "3 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Results: Train Loss: 0.1650 | Test Loss: 0.5716 | Test Acc: 83.31%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "4 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 782/782 [08:11<00:00,  1.59it/s, loss=0.0493]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Results: Train Loss: 0.0756 | Test Loss: 0.5314 | Test Acc: 85.26%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "5 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 782/782 [08:10<00:00,  1.59it/s, loss=0.0167]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Results: Train Loss: 0.0296 | Test Loss: 0.5356 | Test Acc: 85.42%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "6 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 782/782 [08:11<00:00,  1.59it/s, loss=0.00712]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Results: Train Loss: 0.0142 | Test Loss: 0.5436 | Test Acc: 85.78%\n",
            "Model saved to WandB as artifact 'baseline-Davide-collab-test-checkpoints'.\n",
            "7 Saved checkpoint model to WandB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10:  94%|█████████▍| 736/782 [07:42<00:28,  1.60it/s, loss=0.00573]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor, Resize, CenterCrop\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "\n",
        "\n",
        "# Standard CIFAR-100 Normalization\n",
        "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "\n",
        "# Transforms\n",
        "transform_train = Compose([\n",
        "    Resize(256), CenterCrop(224), # Required for DINO\n",
        "    # transforms.RandomHorizontalFlip(), # Optional augmentation\n",
        "    ToTensor(),\n",
        "    Normalize(*stats),\n",
        "])\n",
        "\n",
        "transform_test = Compose([\n",
        "    Resize(256), CenterCrop(224),\n",
        "    ToTensor(),\n",
        "    Normalize(*stats),\n",
        "])\n",
        "\n",
        "# 1. LOAD RAW IMAGES (Required for fine-tuning backbone)\n",
        "# We use the raw dataset, not the precomputed features, so we can backprop through the last layer.\n",
        "train_dataset = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# 2. CALCULATE CENTROIDS (To initialize classifier)\n",
        "print(\"Calculating Centroids for initialization...\")\n",
        "train_data = torch.load(\"features/train_features.pt\")\n",
        "saved_features, saved_labels = train_data[\"features\"], train_data[\"labels\"]\n",
        "\n",
        "num_classes = 100\n",
        "# Assuming features are dim 384 for ViT-S\n",
        "feature_dim = saved_features.shape[1]\n",
        "centroids = torch.zeros((num_classes, feature_dim))\n",
        "\n",
        "for c in range(num_classes):\n",
        "    # Select features belonging to class c\n",
        "    class_features = saved_features[saved_labels == c]\n",
        "    if len(class_features) > 0:\n",
        "        # I computed the centroids with the paper herding method, but you can also just do the mean\n",
        "        # centroids[c] = torch.mean(class_features, dim=0)\n",
        "        centroids[c] = compute_centroid(class_features, class_features.shape[0],feature_dim,DEVICE)\n",
        "\n",
        "# Normalize centroids (DINO features are often cosine-similar)\n",
        "centroids = F.normalize(centroids, p=2, dim=1)\n",
        "print(\"Centroids calculated.\")\n",
        "\n",
        "# Construct the fixed linear layer\n",
        "classifier_weights = centroids # If it's already a tensor\n",
        "\n",
        "LinearLayer = nn.Linear(384, 100)\n",
        "\n",
        "# Load the weights\n",
        "with torch.no_grad():\n",
        "    LinearLayer.weight.copy_(classifier_weights)\n",
        "    LinearLayer.bias.zero_()\n",
        "\n",
        "# DO NOT FREEZE THE LAYER\n",
        "# Allow the centroids to adjust as the backbone changes\n",
        "# for param in LinearLayer.parameters():\n",
        "#    param.requires_grad = False  <-- COMMENT THIS OUT\n",
        "\n",
        "def train(lr, momentum, weight_decay, epochs, centroids):\n",
        "    best_accuracy = 0.0\n",
        "    patience_counter = 0\n",
        "    run_id = f\"run-222-centralized-dino-icarl-cifar100-lr{lr}-mom{momentum}-wd{weight_decay}\"\n",
        "    run = wandb.init(\n",
        "        entity=ENTITY,\n",
        "        project=PROJECT,\n",
        "        group=GROUP,\n",
        "        name=f\"centralized-dino-icarl-cifar100-lr{lr}-mom{momentum}-wd{weight_decay}\",\n",
        "        id=run_id,\n",
        "        resume=\"allow\",\n",
        "        mode=\"online\",\n",
        "    )\n",
        "\n",
        "    # Initialize model with the frozen centroid head\n",
        "    model = CustomDino(num_classes=100, frozen_head=LinearLayer).to(DEVICE)\n",
        "\n",
        "    # Load checkpoint (if any)\n",
        "    checkpoint = load_checkpoint_from_wandb(run, model, \"model.pth\")\n",
        "    start_epoch = 0\n",
        "    if checkpoint is not None:\n",
        "        checkpoint_dict, artifact = checkpoint\n",
        "        model.load_state_dict(checkpoint_dict['model'])\n",
        "        start_epoch = artifact.metadata[\"epoch\"] + 1\n",
        "        print(f\"Resuming from epoch {start_epoch}\")\n",
        "    else:\n",
        "        print(\"Starting from scratch\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # CRITICAL FIX 3: Add the HEAD parameters to the optimizer\n",
        "    # We use a slightly higher LR for the head usually, but same LR is fine for now\n",
        "    optimizer = optim.SGD(\n",
        "        list(model.backbone.parameters()) + list(model.head.parameters()) + [model.scale],\n",
        "        lr=lr,\n",
        "        momentum=momentum,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "    # We don't need centroids in the loop anymore; they are embedded in the model.head\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        # --- TRAINING ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        pbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Model returns Logits (scores), not features\n",
        "            outputs = model(images)\n",
        "\n",
        "            # CrossEntropy expects (Logits, Class_Indices)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        scheduler.step()\n",
        "        avg_train_loss = running_loss / len(trainloader)\n",
        "\n",
        "        # --- EVALUATION ---\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "                # 1. Forward Pass\n",
        "                # The Frozen Linear Layer calculates the similarity to centroids for us.\n",
        "                outputs = model(images) # Shape: [Batch_Size, 100]\n",
        "\n",
        "                # 2. Loss\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                # 3. Accuracy\n",
        "                # The class with the highest score (dot product) is the nearest centroid.\n",
        "                # No need for manual torch.cdist calculation.\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        avg_test_loss = test_loss / len(testloader)\n",
        "        acc = 100. * correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1} Results: Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f} | Test Acc: {acc:.2f}%\")\n",
        "\n",
        "        # Checkpointing\n",
        "        if acc > best_accuracy:\n",
        "            best_accuracy = acc\n",
        "            save_checkpoint_to_wandb(run, {\n",
        "                'model': model.state_dict(),\n",
        "            }, \"model.pth\", {\n",
        "                \"task\": model,\n",
        "                \"accuracy\": acc,\n",
        "                \"epoch\": epoch\n",
        "            })\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter > PATIENCE:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        print(epoch, \"Saved checkpoint model to WandB.\")\n",
        "\n",
        "train(\n",
        "    lr=LR,\n",
        "    momentum=MOMENTUM,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    epochs=EPOCHS,\n",
        "    centroids=centroids\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}