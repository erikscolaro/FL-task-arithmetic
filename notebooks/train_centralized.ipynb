{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madrientrahan\u001b[0m (\u001b[33maml-fl-project\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/notebooks/wandb/run-20251207_182958-run-1-icarl_cifar100</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100' target=\"_blank\">iCaRL_CIFAR100</a></strong> to <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">iCaRL_CIFAR100</strong> at: <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100</a><br> View project at: <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251207_182958-run-1-icarl_cifar100/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/notebooks/wandb/run-20251207_183002-run-0-dino-icarl-cifar100-lr0.01-mom0.9-wd0.0005</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-0-dino-icarl-cifar100-lr0.01-mom0.9-wd0.0005' target=\"_blank\">dino-icarl-cifar100-lr0.01-mom0.9-wd0.0005</a></strong> to <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-0-dino-icarl-cifar100-lr0.01-mom0.9-wd0.0005' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-0-dino-icarl-cifar100-lr0.01-mom0.9-wd0.0005</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adrientrahan/.cache/torch/hub/facebookresearch_dino_main\n",
      "Using cache found in /Users/adrientrahan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run (run-1-icarl_cifar100) is finished. The call to `use_artifact` will be ignored. Please make sure that you are using an active run.\n",
      "Model checkpoint not found on WandB. Run (run-1-icarl_cifar100) is finished. The call to `use_artifact` will be ignored. Please make sure that you are using an active run.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 140\u001b[0m\n\u001b[1;32m    131\u001b[0m         save_checkpoint_to_wandb(run, {\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m    133\u001b[0m         }, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    135\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc,\n\u001b[1;32m    136\u001b[0m         })\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mprint\u001b[39m(epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved checkpoint model to WandB.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMOMENTUM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWEIGHT_DECAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(lr, momentum, weight_decay, epochs)\u001b[0m\n\u001b[1;32m     50\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun-0-dino-icarl-cifar100-lr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-mom\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmomentum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-wd\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m run \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m     52\u001b[0m     entity\u001b[38;5;241m=\u001b[39mENTITY,\n\u001b[1;32m     53\u001b[0m     project\u001b[38;5;241m=\u001b[39mPROJECT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 61\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDinoIcarlModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m load_checkpoint_from_wandb(\n\u001b[1;32m     64\u001b[0m     run,\n\u001b[1;32m     65\u001b[0m     model,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ecole/AML/project/FL-task-arithmetic/models/dino_icarl.py:13\u001b[0m, in \u001b[0;36mDinoIcarlModel.__init__\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdino_backbone \u001b[38;5;241m=\u001b[39m Dino\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39micarl_head \u001b[38;5;241m=\u001b[39m \u001b[43mget_trained_icarl_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ecole/AML/project/FL-task-arithmetic/models/icarl_head.py:175\u001b[0m, in \u001b[0;36mget_trained_icarl_classifier\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    165\u001b[0m icarl \u001b[38;5;241m=\u001b[39m Icarl(\n\u001b[1;32m    166\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m    167\u001b[0m     memory_size\u001b[38;5;241m=\u001b[39mTOTAL_EXEMPLARS_VECTORS,\n\u001b[1;32m    168\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    169\u001b[0m )\n\u001b[1;32m    170\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m load_checkpoint_from_wandb(\n\u001b[1;32m    171\u001b[0m     run,\n\u001b[1;32m    172\u001b[0m     icarl,\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m )\n\u001b[0;32m--> 175\u001b[0m checkpoint_dict, artifact \u001b[38;5;241m=\u001b[39m checkpoint\n\u001b[1;32m    176\u001b[0m icarl\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m icarl\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mclassifier\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, Resize, CenterCrop\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, cast\n",
    "import wandb\n",
    "from models.dino_icarl import DinoIcarlModel\n",
    "from utilities.wandb_utils import load_checkpoint_from_wandb, save_checkpoint_to_wandb\n",
    "\n",
    "ENTITY = \"aml-fl-project\"\n",
    "PROJECT = \"fl-task-arithmetic\"\n",
    "GROUP = \"icarl-cifar100\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LR  = 0.01           # Learning Rate (Tune this: 0.1, 0.01, 0.001)\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "EPOCHS = 20         # Increase to 100+ for final results\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Standard CIFAR-100 Normalization\n",
    "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "\n",
    "# Transforms\n",
    "transform_train = Compose([\n",
    "    Resize(256), CenterCrop(224), # Required for DINO\n",
    "    # transforms.RandomHorizontalFlip(), # Optional augmentation\n",
    "    ToTensor(),\n",
    "    Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    Resize(256), CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    Normalize(*stats),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "def train(lr, momentum, weight_decay, epochs):\n",
    "    run_id = f\"run-0-dino-icarl-cifar100-lr{lr}-mom{momentum}-wd{weight_decay}\"\n",
    "    run = wandb.init(\n",
    "        entity=ENTITY,\n",
    "        project=PROJECT,\n",
    "        group=GROUP,\n",
    "        name=f\"dino-icarl-cifar100-lr{lr}-mom{momentum}-wd{weight_decay}\",\n",
    "        id=run_id,\n",
    "        resume=\"allow\",\n",
    "        mode=\"online\",\n",
    "    )\n",
    "\n",
    "    model = DinoIcarlModel(device=DEVICE)\n",
    "\n",
    "    checkpoint, _ = load_checkpoint_from_wandb(\n",
    "        run,\n",
    "        model,\n",
    "        \"model.pth\"\n",
    "    )\n",
    "    start_epoch = 0\n",
    "    if checkpoint is not None:\n",
    "        checkpoint_dict, artifact = checkpoint\n",
    "        model.load_state_dict(checkpoint_dict['model'])\n",
    "        start_epoch = artifact.metadata[\"epoch\"] + 1\n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "    else:\n",
    "        print(\"Starting from scratch\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Progress bar for training\n",
    "        pbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_train_loss = running_loss / len(trainloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # 5. Evaluation\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        avg_test_loss = test_loss / len(testloader)\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_accs.append(acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Results: Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f} | Test Acc: {acc:.2f}%\")\n",
    "\n",
    "\n",
    "        save_checkpoint_to_wandb(run, {\n",
    "            'model': model.state_dict(),\n",
    "        }, f\"model.pth\", {\n",
    "            \"task\": model,\n",
    "            \"accuracy\": acc,\n",
    "        })\n",
    "        print(epoch, \"Saved checkpoint model to WandB.\")\n",
    "\n",
    "    \n",
    "train(LR, MOMENTUM, WEIGHT_DECAY, EPOCHS)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-task-arithmetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
