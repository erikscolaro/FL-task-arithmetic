{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364560f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">iCaRL_CIFAR100</strong> at: <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100</a><br> View project at: <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251207_152246-run-1-icarl_cifar100/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/notebooks/wandb/run-20251207_152320-run-1-icarl_cifar100</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100' target=\"_blank\">iCaRL_CIFAR100</a></strong> to <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adrientrahan/.cache/torch/hub/facebookresearch_dino_main\n",
      "Using cache found in /Users/adrientrahan/.cache/torch/hub/facebookresearch_dino_main\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'icarl-cifar100-checkpoints:latest', 223.13MB. 1 files...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 00:00:00.2 (1035.7MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/notebooks/artifacts/icarl-cifar100-checkpoints:v1/model.pth\n",
      "Successfully loaded model from: /Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/notebooks/artifacts/icarl-cifar100-checkpoints:v1/model.pth\n",
      "Resuming from task 2\n",
      "\n",
      "================ TASK 3/20 : Classes [10, 11, 12, 13, 14] ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 1423.5848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 314.4528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss 56.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss 12.5427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss 6.9069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss 4.8334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss 1.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss 1.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss 0.6945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss 0.2994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss 0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss 0.0076\n",
      "Reducing exemplars to 10 per class...\n",
      "Constructing 10 exemplars vectors per class number 10\n",
      "Constructing 10 exemplars vectors per class number 11\n",
      "Constructing 10 exemplars vectors per class number 12\n",
      "Constructing 10 exemplars vectors per class number 13\n",
      "Constructing 10 exemplars vectors per class number 14\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:48<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 Accuracy (NME): 77.73%\n",
      "Model saved to WandB as artifact 'icarl-cifar100-checkpoints'.\n",
      "2 Saved checkpoint model to WandB.\n",
      "\n",
      "================ TASK 4/20 : Classes [15, 16, 17, 18, 19] ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 1539.5116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 340.4018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss 33.1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss 12.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss 7.6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss 4.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss 2.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss 1.6307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss 1.3382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss 0.3821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss 0.0608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss 0.0081\n",
      "Reducing exemplars to 10 per class...\n",
      "Constructing 10 exemplars vectors per class number 15\n",
      "Constructing 10 exemplars vectors per class number 16\n",
      "Constructing 10 exemplars vectors per class number 17\n",
      "Constructing 10 exemplars vectors per class number 18\n",
      "Constructing 10 exemplars vectors per class number 19\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:00<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 Accuracy (NME): 72.65%\n",
      "Model saved to WandB as artifact 'icarl-cifar100-checkpoints'.\n",
      "3 Saved checkpoint model to WandB.\n",
      "\n",
      "================ TASK 5/20 : Classes [20, 21, 22, 23, 24] ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 1397.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20:  53%|█████▎    | 23/43 [02:03<01:50,  5.53s/it]"
     ]
    }
   ],
   "source": [
    "from data.icarl_dataset import iCaRLDataset, get_data_for_classes, extract_images_from_subset\n",
    "from time import sleep\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, Resize, CenterCrop\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "from models.icarl_head import IcarlModel, Icarl\n",
    "import wandb\n",
    "from utilities.wandb_utils import load_checkpoint_from_wandb, save_checkpoint_to_wandb\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "RUN_ID = \"run-1-icarl_cifar100\"\n",
    "ENTITY = \"aml-fl-project\"\n",
    "PROJECT = \"fl-task-arithmetic\"\n",
    "GROUP = \"icarl-cifar100\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TOTAL_EXEMPLARS_VECTORS = 1000\n",
    "TASKS = 20\n",
    "CLASSES_PER_TASK = 100 // TASKS\n",
    "\n",
    "EPOCHS = 20\n",
    "LR = 0.01\n",
    "WEIGHT_DECAY = 1e-5\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "\n",
    "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "transform = Compose([\n",
    "    Resize(256), CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load FULL Datasets\n",
    "train_ds = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "test_ds = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "run = wandb.init(\n",
    "    entity=ENTITY,\n",
    "    project=PROJECT,\n",
    "    group=GROUP,\n",
    "    name=\"iCaRL_CIFAR100\",\n",
    "    id=RUN_ID,\n",
    "    resume=\"allow\",\n",
    "    mode=\"online\",\n",
    ")\n",
    "\n",
    "# for artifact in wandb.Api().run(f\"{ENTITY}/{PROJECT}/{RUN_ID}\").logged_artifacts():\n",
    "#     artifact.delete()\n",
    "\n",
    "\n",
    "# Initialize iCaRL\n",
    "icarl = Icarl(\n",
    "    num_classes=100,\n",
    "    memory_size=TOTAL_EXEMPLARS_VECTORS,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "checkpoint = load_checkpoint_from_wandb(\n",
    "    run,\n",
    "    icarl,\n",
    "    \"model.pth\"\n",
    ")\n",
    "start_task = 0\n",
    "if checkpoint is not None:\n",
    "    checkpoint_dict, artifact = checkpoint\n",
    "    icarl.load_state_dict(checkpoint_dict['model'])\n",
    "    icarl.exemplar_sets = [[img.to(icarl.device) for img in class_set] for class_set in checkpoint_dict['exemplar_sets']]\n",
    "\n",
    "    start_task = artifact.metadata[\"task\"] + 1\n",
    "    icarl.is_old_model_usable = True\n",
    "    print(f\"Resuming from task {start_task}\")\n",
    "else:\n",
    "    print(\"Starting from scratch\")\n",
    "\n",
    "for task_id in range(start_task, TASKS):\n",
    "    # 1. Define Classes for this Task\n",
    "    start_class = task_id * CLASSES_PER_TASK\n",
    "    end_class = (task_id + 1) * CLASSES_PER_TASK\n",
    "    new_classes = list(range(start_class, end_class))\n",
    "\n",
    "    print(f\"\\n================ TASK {task_id+1}/{TASKS} : Classes {new_classes} ================\")\n",
    "\n",
    "    # 2. Prepare Training Data (New Data + Exemplars)\n",
    "    # Get subset of ONLY new classes\n",
    "    task_data_subset = get_data_for_classes(train_ds, new_classes)\n",
    "\n",
    "    # Create a list of (img, label) for the custom dataset\n",
    "    # We iterate once to cache them (RAM intensive but simpler code)\n",
    "    new_data_list = []\n",
    "    for i in range(len(task_data_subset)):\n",
    "        img, target = task_data_subset[i]\n",
    "        new_data_list.append((img.to(icarl.device), target))\n",
    "\n",
    "    # Create Hybrid Dataset\n",
    "    train_dataset = iCaRLDataset(new_data_list, icarl.exemplar_sets)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "    # 3. Train (Update Representation) \n",
    "    #Only train the classifier parameters\n",
    "    optimizer = optim.SGD(icarl.model.classifier.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "    # Scheduler helps convergence\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    icarl.model.train()\n",
    "    if icarl.is_old_model_usable:\n",
    "        icarl.old_model.eval()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "            images = images.to(icarl.device)\n",
    "            labels = labels.to(icarl.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            logits, _ = icarl.model(images)\n",
    "\n",
    "            # --- Loss Calculation ---\n",
    "            # A. Classification Loss (Cross Entropy on all visible classes)\n",
    "            loss_cls = F.cross_entropy(logits, labels)\n",
    "\n",
    "            # B. Distillation Loss (on OLD classes only)\n",
    "            loss_dist = torch.tensor(0.).to(icarl.device)\n",
    "            if icarl.is_old_model_usable:\n",
    "                # Get old logits\n",
    "                with torch.no_grad():\n",
    "                    old_logits, _ = icarl.old_model(images)\n",
    "\n",
    "                # Sigmoid Distillation (Rebuffi et al. 2017)\n",
    "                # We compute BCE between the sigmoid outputs of the new model and the old model\n",
    "                # solely for the classes the old model knew.\n",
    "                # Usually iCaRL assumes specific output nodes. Here we map indices.\n",
    "                # We assume indices 0 to (start of new task) are old classes.\n",
    "\n",
    "                # Create a mask for old classes (e.g., 0 to 10, then 0 to 20...)\n",
    "                # The 'old_logits' typically has size [B, num_classes] same as current if architecture is fixed\n",
    "                # Or [B, old_num_classes] if it grew. DINO linear layer is usually fixed size or grows.\n",
    "                # Here we assume fixed size 100 for simplicity.\n",
    "\n",
    "                # Calculate Distillation:\n",
    "                # T=1 is standard for iCaRL's sigmoid distillation\n",
    "                #[:, :start_new_task] Are all the old classes the new model should not forget\n",
    "                start_new_task = new_classes[0]\n",
    "                if start_new_task > 0:\n",
    "                    dist_target = torch.sigmoid(old_logits[:, :start_new_task])\n",
    "                    dist_pred = torch.sigmoid(logits[:, :start_new_task])\n",
    "                    loss_dist = F.binary_cross_entropy(dist_pred, dist_target)\n",
    "\n",
    "            loss = loss_cls + loss_dist\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch}: Loss {total_loss:.4f}\")\n",
    "    icarl.old_model = deepcopy(icarl.model)\n",
    "    icarl.is_old_model_usable = True\n",
    "        \n",
    "\n",
    "    # 4. Exemplar Management\n",
    "    # A. Reduce old sets\n",
    "    m = TOTAL_EXEMPLARS_VECTORS // 100\n",
    "    icarl.reduce_exemplar_sets(m)\n",
    "\n",
    "    # B. Construct new sets\n",
    "    for c in new_classes:\n",
    "        # Extract images for specific class c\n",
    "        # (Re-extract from subset for clean separation)\n",
    "        class_subset = get_data_for_classes(train_ds, [c])\n",
    "        images_c = extract_images_from_subset(class_subset)\n",
    "        icarl.construct_exemplar_sets(images_c, m, transform,c)\n",
    "\n",
    "    # 5. Evaluate on ALL classes seen so far\n",
    "    print(\"Evaluating...\")\n",
    "    seen_classes = list(range(0, end_class))\n",
    "    test_subset = get_data_for_classes(test_ds, seen_classes)\n",
    "    test_loader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, lbls in tqdm(test_loader):\n",
    "        imgs = imgs.to(icarl.device)\n",
    "        lbls = lbls.to(icarl.device)\n",
    "        logits, _ = icarl(imgs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += preds.eq(lbls).sum().item()\n",
    "        total += lbls.size(0)\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Task {task_id+1} Accuracy (NME): {acc:.2f}%\")\n",
    "\n",
    "\n",
    "    save_checkpoint_to_wandb(run, {\n",
    "        'model': icarl.state_dict(),\n",
    "        'exemplar_sets': [[img.cpu() for img in class_set] for class_set in icarl.exemplar_sets],\n",
    "    }, f\"model.pth\", {\n",
    "        \"task\": task_id,\n",
    "        \"accuracy\": acc,\n",
    "    })\n",
    "    print(task_id, \"Saved checkpoint model to WandB.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-task-arithmetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
