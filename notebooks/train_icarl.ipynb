{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madrientrahan\u001b[0m (\u001b[33maml-fl-project\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/notebooks/wandb/run-20251207_141238-run-1-icarl_cifar100</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100' target=\"_blank\">iCaRL_CIFAR100</a></strong> to <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100' target=\"_blank\">https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/run-1-icarl_cifar100</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adrientrahan/.cache/torch/hub/facebookresearch_dino_main\n",
      "Using cache found in /Users/adrientrahan/.cache/torch/hub/facebookresearch_dino_main\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'icarl-cifar100-checkpoints:latest', 165.69MB. 1 files...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 00:00:00.5 (363.8MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/notebooks/artifacts/icarl-cifar100-checkpoints:v1/model.pth\n",
      "Successfully loaded model from: /Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/notebooks/artifacts/icarl-cifar100-checkpoints:v1/model.pth\n",
      "[]\n",
      "Resuming from task 2\n",
      "\n",
      "================ TASK 3/20 : Classes [10, 11, 12, 13, 14] ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 1265.4523\n",
      "Reducing exemplars to 10 per class...\n",
      "Constructing 10 exemplars vectors per class number 10\n",
      "Constructing 10 exemplars vectors per class number 11\n",
      "Constructing 10 exemplars vectors per class number 12\n",
      "Constructing 10 exemplars vectors per class number 13\n",
      "Constructing 10 exemplars vectors per class number 14\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:48<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 Accuracy (NME): 32.33%\n",
      "Model saved to WandB as artifact 'icarl-cifar100-checkpoints'.\n",
      "2 Saved checkpoint model to WandB.\n",
      "\n",
      "================ TASK 4/20 : Classes [15, 16, 17, 18, 19] ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   5%|▌         | 2/40 [00:12<03:49,  6.04s/it]libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1165ac310>\n",
      "socket.send() raised exception.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1627, in _shutdown_workers\n",
      "socket.send() raised exception.\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/adrientrahan/.local/share/uv/python/cpython-3.10.17-macos-aarch64-none/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/adrientrahan/.local/share/uv/python/cpython-3.10.17-macos-aarch64-none/lib/python3.10/multiprocessing/popen_fork.py\", line 43, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/Users/adrientrahan/.local/share/uv/python/cpython-3.10.17-macos-aarch64-none/lib/python3.10/multiprocessing/popen_fork.py\", line 27, in poll\n",
      "socket.send() raised exception.\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "  File \"/Users/adrientrahan/Documents/ecole/AML/project/FL-task-arithmetic/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 33879) is killed by signal: Abort trap: 6. \n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from data.icarl_dataset import iCaRLDataset, get_data_for_classes, extract_images_from_subset\n",
    "from time import sleep\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, Resize, CenterCrop\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "from models.icarl_head import IcarlModel, Icarl\n",
    "import wandb\n",
    "from utilities.wandb_utils import load_checkpoint_from_wandb, save_checkpoint_to_wandb\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "RUN_ID = \"run-1-icarl_cifar100\"\n",
    "ENTITY = \"aml-fl-project\"\n",
    "PROJECT = \"fl-task-arithmetic\"\n",
    "GROUP = \"icarl-cifar100\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TOTAL_EXEMPLARS_VECTORS = 1000\n",
    "TASKS = 20\n",
    "CLASSES_PER_TASK = 100 // TASKS\n",
    "\n",
    "EPOCHS = 20\n",
    "LR = 0.01\n",
    "WEIGHT_DECAY = 1e-5\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "\n",
    "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "transform = Compose([\n",
    "    Resize(256), CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load FULL Datasets\n",
    "train_ds = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "test_ds = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "run = wandb.init(\n",
    "    entity=ENTITY,\n",
    "    project=PROJECT,\n",
    "    group=GROUP,\n",
    "    name=\"iCaRL_CIFAR100\",\n",
    "    id=RUN_ID,\n",
    "    resume=\"allow\",\n",
    "    mode=\"online\",\n",
    ")\n",
    "\n",
    "# for artifact in wandb.Api().run(f\"{ENTITY}/{PROJECT}/{RUN_ID}\").logged_artifacts():\n",
    "#     artifact.delete()\n",
    "\n",
    "\n",
    "# Initialize iCaRL\n",
    "icarl = Icarl(\n",
    "    num_classes=100,\n",
    "    memory_size=TOTAL_EXEMPLARS_VECTORS,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "checkpoint = load_checkpoint_from_wandb(\n",
    "    run,\n",
    "    icarl,\n",
    "    \"model.pth\"\n",
    ")\n",
    "start_task = 0\n",
    "if checkpoint is not None:\n",
    "    checkpoint_dict, artifact = checkpoint\n",
    "    icarl.load_state_dict(checkpoint_dict['model'])\n",
    "    icarl.exemplar_sets = [[img.to(icarl.device) for img in class_set] for class_set in checkpoint_dict['exemplar_sets']]\n",
    "\n",
    "    start_task = artifact.metadata[\"task\"] + 1\n",
    "    icarl.is_old_model_usable = True\n",
    "    print(f\"Resuming from task {start_task}\")\n",
    "else:\n",
    "    print(\"Starting from scratch\")\n",
    "\n",
    "for task_id in range(start_task, TASKS):\n",
    "    # 1. Define Classes for this Task\n",
    "    start_class = task_id * CLASSES_PER_TASK\n",
    "    end_class = (task_id + 1) * CLASSES_PER_TASK\n",
    "    new_classes = list(range(start_class, end_class))\n",
    "\n",
    "    print(f\"\\n================ TASK {task_id+1}/{TASKS} : Classes {new_classes} ================\")\n",
    "\n",
    "    # 2. Prepare Training Data (New Data + Exemplars)\n",
    "    # Get subset of ONLY new classes\n",
    "    task_data_subset = get_data_for_classes(train_ds, new_classes)\n",
    "\n",
    "    # Create a list of (img, label) for the custom dataset\n",
    "    # We iterate once to cache them (RAM intensive but simpler code)\n",
    "    new_data_list = []\n",
    "    for i in range(len(task_data_subset)):\n",
    "        img, target = task_data_subset[i]\n",
    "        new_data_list.append((img, target))\n",
    "\n",
    "    # Create Hybrid Dataset\n",
    "    train_dataset = iCaRLDataset(new_data_list, icarl.exemplar_sets)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "    # 3. Train (Update Representation) \n",
    "    #Only train the classifier parameters\n",
    "    optimizer = optim.SGD(icarl.model.classifier.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "    # Scheduler helps convergence\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    icarl.model.train()\n",
    "    if icarl.is_old_model_usable:\n",
    "        icarl.old_model.eval()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "            images = images.to(icarl.device)\n",
    "            labels = labels.to(icarl.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            logits, _ = icarl.model(images)\n",
    "\n",
    "            # --- Loss Calculation ---\n",
    "            # A. Classification Loss (Cross Entropy on all visible classes)\n",
    "            loss_cls = F.cross_entropy(logits, labels)\n",
    "\n",
    "            # B. Distillation Loss (on OLD classes only)\n",
    "            loss_dist = torch.tensor(0.).to(icarl.device)\n",
    "            if icarl.is_old_model_usable:\n",
    "                # Get old logits\n",
    "                with torch.no_grad():\n",
    "                    old_logits, _ = icarl.old_model(images)\n",
    "\n",
    "                # Sigmoid Distillation (Rebuffi et al. 2017)\n",
    "                # We compute BCE between the sigmoid outputs of the new model and the old model\n",
    "                # solely for the classes the old model knew.\n",
    "                # Usually iCaRL assumes specific output nodes. Here we map indices.\n",
    "                # We assume indices 0 to (start of new task) are old classes.\n",
    "\n",
    "                # Create a mask for old classes (e.g., 0 to 10, then 0 to 20...)\n",
    "                # The 'old_logits' typically has size [B, num_classes] same as current if architecture is fixed\n",
    "                # Or [B, old_num_classes] if it grew. DINO linear layer is usually fixed size or grows.\n",
    "                # Here we assume fixed size 100 for simplicity.\n",
    "\n",
    "                # Calculate Distillation:\n",
    "                # T=1 is standard for iCaRL's sigmoid distillation\n",
    "                #[:, :start_new_task] Are all the old classes the new model should not forget\n",
    "                start_new_task = new_classes[0]\n",
    "                if start_new_task > 0:\n",
    "                    dist_target = torch.sigmoid(old_logits[:, :start_new_task])\n",
    "                    dist_pred = torch.sigmoid(logits[:, :start_new_task])\n",
    "                    loss_dist = F.binary_cross_entropy(dist_pred, dist_target)\n",
    "\n",
    "            loss = loss_cls + loss_dist\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch}: Loss {total_loss:.4f}\")\n",
    "    icarl.old_model = deepcopy(icarl.model)\n",
    "    icarl.is_old_model_usable = True\n",
    "        \n",
    "\n",
    "    # 4. Exemplar Management\n",
    "    # A. Reduce old sets\n",
    "    m = TOTAL_EXEMPLARS_VECTORS // 100\n",
    "    icarl.reduce_exemplar_sets(m)\n",
    "\n",
    "    # B. Construct new sets\n",
    "    for c in new_classes:\n",
    "        # Extract images for specific class c\n",
    "        # (Re-extract from subset for clean separation)\n",
    "        class_subset = get_data_for_classes(train_ds, [c])\n",
    "        images_c = extract_images_from_subset(class_subset)\n",
    "        icarl.construct_exemplar_sets(images_c, m, transform,c)\n",
    "\n",
    "    # 5. Evaluate on ALL classes seen so far\n",
    "    print(\"Evaluating...\")\n",
    "    seen_classes = list(range(0, end_class))\n",
    "    test_subset = get_data_for_classes(test_ds, seen_classes)\n",
    "    test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, lbls in tqdm(test_loader):\n",
    "        imgs = imgs.to(icarl.device)\n",
    "        lbls = lbls.to(icarl.device)\n",
    "        logits, _ = icarl(imgs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += preds.eq(lbls).sum().item()\n",
    "        total += lbls.size(0)\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Task {task_id+1} Accuracy (NME): {acc:.2f}%\")\n",
    "\n",
    "\n",
    "    save_checkpoint_to_wandb(run, {\n",
    "        'model': icarl.state_dict(),\n",
    "        'exemplar_sets': [[img.cpu() for img in class_set] for class_set in icarl.exemplar_sets],\n",
    "    }, f\"model.pth\", {\n",
    "        \"task\": task_id,\n",
    "        \"accuracy\": acc,\n",
    "    })\n",
    "    print(task_id, \"Saved checkpoint model to WandB.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-task-arithmetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
