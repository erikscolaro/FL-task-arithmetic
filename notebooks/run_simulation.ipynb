{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3afbedf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading project configuration... \n",
      "Success\n",
      "Wandb config:\n",
      "\tentity=aml-fl-project\n",
      "\tproject=fl-task-arithmetic\n",
      "\tgroup=experiment-test\n",
      "\tnotes=Test\n",
      "\tresume=allow\n",
      "\trun_id=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: erikscolaro31 (aml-fl-project) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n",
      "wandb: setting up run fl-task-arithmetic-experiment-test-0-server\n",
      "/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n",
      "wandb: Tracking run with wandb version 0.23.0\n",
      "wandb: Run data is saved locally in /home/einrich99/Progetti/FL-task-arithmetic/wandb/run-20251128_192032-fl-task-arithmetic-experiment-test-0-server\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Resuming run server\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/aml-fl-project/fl-task-arithmetic\n",
      "wandb: üöÄ View run at https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/fl-task-arithmetic-experiment-test-0-server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I find a previous run on the cloud. I'll resume from round 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  self.FromDatetime(datetime.datetime.utcnow())\n",
      "wandb:   1 of 1 files downloaded.  \n",
      "\u001b[92mINFO \u001b[0m:      Starting CustomFedAvg strategy:\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îú‚îÄ‚îÄ Number of rounds: 2\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îú‚îÄ‚îÄ ArrayRecord (0.27 MB)\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îú‚îÄ‚îÄ ConfigRecord (train): {'lr': 0.01, 'server-round': 2}\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îú‚îÄ‚îÄ ConfigRecord (evaluate): (empty!)\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îú‚îÄ‚îÄ> Sampling:\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îÇ\t‚îú‚îÄ‚îÄFraction: train (0.20) | evaluate ( 1.00)\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îÇ\t‚îú‚îÄ‚îÄMinimum nodes: train (2) | evaluate (2)\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îÇ\t‚îî‚îÄ‚îÄMinimum available nodes: 2\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îî‚îÄ‚îÄ> Keys in records:\n",
      "\u001b[92mINFO \u001b[0m:      \t\t‚îú‚îÄ‚îÄ Weighted by: 'num-examples'\n",
      "\u001b[92mINFO \u001b[0m:      \t\t‚îú‚îÄ‚îÄ ArrayRecord key: 'arrays'\n",
      "\u001b[92mINFO \u001b[0m:      \t\t‚îî‚îÄ‚îÄ ConfigRecord key: 'config'\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1/2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_train: Sampled 2 nodes (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from: /home/einrich99/Progetti/FL-task-arithmetic/artifacts/experiment-test-checkpoints:v1/model.pth\n",
      "correcly created the state dict for the global model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=29571)\u001b[0m /home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr_datasets/partitioner/pathological_partitioner.py:188: UserWarning: Classes: [0, 1, 2, 3, 6, 9, 10, 11, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 46, 48, 50, 52, 55, 56, 57, 59, 60, 64, 65, 66, 67, 72, 76, 77, 78, 80, 81, 82, 85, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99] will NOT be used due to the chosen configuration. If it is undesired behavior consider setting 'first_class_deterministic_assignment=True' which in case when the number of classes is smaller than the number of partitions will utilize all the classes for the created partitions.\n",
      "\u001b[36m(ClientAppActor pid=29571)\u001b[0m   warnings.warn(\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_train: Received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îî‚îÄ‚îÄ> Aggregated MetricRecord: {'train_loss': 2.5796877975009096}\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: Sampled 2 nodes (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: Received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îî‚îÄ‚îÄ> Aggregated MetricRecord: {'eval_loss': 3.6751458280753297, 'eval_acc': 0.05438701923076923}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2/2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_train: Sampled 2 nodes (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_train: Received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îî‚îÄ‚îÄ> Aggregated MetricRecord: {'train_loss': 2.5372166312277606}\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: Sampled 2 nodes (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: Received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \t‚îî‚îÄ‚îÄ> Aggregated MetricRecord: {'eval_loss': 3.627116979184083, 'eval_acc': 0.05799278846153846}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Strategy execution finished in 26.80s\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Final results:\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      \tGlobal Arrays:\n",
      "\u001b[92mINFO \u001b[0m:      \t\tArrayRecord (0.267 MB)\n",
      "\u001b[92mINFO \u001b[0m:      \t\n",
      "\u001b[92mINFO \u001b[0m:      \tAggregated ClientApp-side Train Metrics:\n",
      "\u001b[92mINFO \u001b[0m:      \t{1: {'train_loss': '2.5797e+00'}, 2: {'train_loss': '2.5372e+00'}}\n",
      "\u001b[92mINFO \u001b[0m:      \t\n",
      "\u001b[92mINFO \u001b[0m:      \tAggregated ClientApp-side Evaluate Metrics:\n",
      "\u001b[92mINFO \u001b[0m:      \t{ 1: {'eval_acc': '5.4387e-02', 'eval_loss': '3.6751e+00'},\n",
      "\u001b[92mINFO \u001b[0m:      \t  2: {'eval_acc': '5.7993e-02', 'eval_loss': '3.6271e+00'}}\n",
      "\u001b[92mINFO \u001b[0m:      \t\n",
      "\u001b[92mINFO \u001b[0m:      \tServerApp-side Evaluate Metrics:\n",
      "\u001b[92mINFO \u001b[0m:      \t{}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving final model to wandb...\n",
      "Model saved to WandB as artifact 'experiment-test-checkpoints'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: uploading artifact experiment-test-checkpoints; updating run metadata\n",
      "wandb: uploading artifact experiment-test-checkpoints; uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "wandb: uploading artifact experiment-test-checkpoints; uploading wandb-summary.json; uploading config.yaml\n",
      "wandb: uploading artifact experiment-test-checkpoints\n",
      "wandb: uploading history steps 102-103, summary, console lines 31-56\n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:   eval_acc ‚ñÅ‚ñà\n",
      "wandb:  eval_loss ‚ñà‚ñÅ\n",
      "wandb:      round ‚ñÅ‚ñÅ‚ñà‚ñà\n",
      "wandb: train_loss ‚ñà‚ñÅ\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:   eval_acc 0.05799\n",
      "wandb:  eval_loss 3.62712\n",
      "wandb:      round 2\n",
      "wandb: train_loss 2.53722\n",
      "wandb: \n",
      "wandb: üöÄ View run server at: https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/fl-task-arithmetic-experiment-test-0-server\n",
      "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/aml-fl-project/fl-task-arithmetic\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20251128_192032-fl-task-arithmetic-experiment-test-0-server/logs\n",
      "\u001b[36m(ClientAppActor pid=29572)\u001b[0m /home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr_datasets/partitioner/pathological_partitioner.py:188: UserWarning: Classes: [0, 1, 2, 3, 6, 9, 10, 11, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 46, 48, 50, 52, 55, 56, 57, 59, 60, 64, 65, 66, 67, 72, 76, 77, 78, 80, 81, 82, 85, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99] will NOT be used due to the chosen configuration. If it is undesired behavior consider setting 'first_class_deterministic_assignment=True' which in case when the number of classes is smaller than the number of partitions will utilize all the classes for the created partitions.\n",
      "\u001b[36m(ClientAppActor pid=29572)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "run_config = \"conf1.toml\"\n",
    "\n",
    "command = f\"cd .. && flwr run --run-config config/{run_config}\"\n",
    "os.system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
