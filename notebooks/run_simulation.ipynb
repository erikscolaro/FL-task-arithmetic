{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afbedf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading project configuration... \n",
      "Success\n",
      "Wandb config:\n",
      "\tentity=aml-fl-project\n",
      "\tproject=fl-task-arithmetic\n",
      "\tgroup=experiment-test3\n",
      "\tnotes=Test\n",
      "\tresume=allow\n",
      "\trun_id=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: erikscolaro31 (aml-fl-project) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n",
      "wandb: setting up run fl-task-arithmetic-experiment-test3-0-server\n",
      "/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n",
      "wandb: Tracking run with wandb version 0.23.0\n",
      "wandb: Run data is saved locally in /home/einrich99/Progetti/FL-task-arithmetic/wandb/run-20251216_164113-fl-task-arithmetic-experiment-test3-0-server\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Resuming run server\n",
      "wandb: â­ï¸ View project at https://wandb.ai/aml-fl-project/fl-task-arithmetic\n",
      "wandb: ðŸš€ View run at https://wandb.ai/aml-fl-project/fl-task-arithmetic/runs/fl-task-arithmetic-experiment-test3-0-server\n",
      "Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n",
      "/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  self.FromDatetime(datetime.datetime.utcnow())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n",
      "Starting from scratch.\n",
      "Model saved to WandB as artifact 'experiment-test3-models'.\n",
      "correcly created the state dict for the global model\n",
      "Server round: 0\n",
      "Error obtaining the test split from the federated dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting CustomFedAvg strategy:\n",
      "\u001b[92mINFO \u001b[0m:      \tâ”œâ”€â”€ Number of rounds: 5\n",
      "\u001b[92mINFO \u001b[0m:      \tâ”œâ”€â”€ ArrayRecord (82.81 MB)\n",
      "\u001b[92mINFO \u001b[0m:      \tâ”œâ”€â”€ ConfigRecord (train): {'lr': 0.01}\n",
      "\u001b[92mINFO \u001b[0m:      \tâ”œâ”€â”€ ConfigRecord (evaluate): (empty!)\n",
      "\u001b[92mINFO \u001b[0m:      \tâ”œâ”€â”€> Sampling:\n",
      "\u001b[92mINFO \u001b[0m:      \tâ”‚\tâ”œâ”€â”€Fraction: train (0.20) | evaluate ( 1.00)\n",
      "\u001b[92mINFO \u001b[0m:      \tâ”‚\tâ”œâ”€â”€Minimum nodes: train (2) | evaluate (2)\n",
      "\u001b[92mINFO \u001b[0m:      \tâ”‚\tâ””â”€â”€Minimum available nodes: 2\n",
      "\u001b[92mINFO \u001b[0m:      \tâ””â”€â”€> Keys in records:\n",
      "\u001b[92mINFO \u001b[0m:      \t\tâ”œâ”€â”€ Weighted by: 'num-examples'\n",
      "\u001b[92mINFO \u001b[0m:      \t\tâ”œâ”€â”€ ArrayRecord key: 'arrays'\n",
      "\u001b[92mINFO \u001b[0m:      \t\tâ””â”€â”€ ConfigRecord key: 'config'\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Initial global evaluation results: {}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1/5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_train: Sampled 2 nodes (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m /home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr_datasets/partitioner/pathological_partitioner.py:188: UserWarning: Classes: [0, 1, 6, 14, 16, 19, 27, 38, 42, 64, 72, 80, 82, 88, 96] will NOT be used due to the chosen configuration. If it is undesired behavior consider setting 'first_class_deterministic_assignment=True' which in case when the number of classes is smaller than the number of partitions will utilize all the classes for the created partitions.\n",
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m   warnings.warn(\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 124, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 189, in process_message\n",
      "    raise ex\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 176, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 124, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 189, in process_message\n",
      "    raise ex\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 176, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_train: Received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      \t> Received error in reply from node 727717302713705008: <class 'ray.exceptions.RayTaskError(ClientAppException)'>:<'\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'>\n",
      "\u001b[92mINFO \u001b[0m:      \t> Received error in reply from node 3634699372066926004: <class 'ray.exceptions.RayTaskError(ClientAppException)'>:<'\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'>\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: Sampled 10 nodes (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: Received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \tâ””â”€â”€> Aggregated MetricRecord: {'eval_loss': 1.696643981072415, 'eval_acc': 0.600627286983795}\n",
      "\u001b[92mINFO \u001b[0m:      Global evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \tâ””â”€â”€> MetricRecord: {}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2/5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_train: Sampled 2 nodes (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round: 1\n",
      "Error obtaining the test split from the federated dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 124, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 189, in process_message\n",
      "    raise ex\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 176, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 124, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 189, in process_message\n",
      "    raise ex\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 176, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_train: Received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      \t> Received error in reply from node 9160483473519721168: <class 'ray.exceptions.RayTaskError(ClientAppException)'>:<'\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'>\n",
      "\u001b[92mINFO \u001b[0m:      \t> Received error in reply from node 3634699372066926004: <class 'ray.exceptions.RayTaskError(ClientAppException)'>:<'\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/clientapp/client_app.py\", line 161, in __call__\n",
      "    return self._registered_funcs[full_name](message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/client_app.py\", line 50, in train\n",
      "    train_loss = train_fn(\n",
      "                 ^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/task.py\", line 124, in train\n",
      "    loss = criterion(net(images), labels)\n",
      "                     ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/FL-task-arithmetic/fl_task_arithmetic/model.py\", line 127, in forward\n",
      "    features = self.backbone(x)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 212, in forward\n",
      "    x = blk(x)\n",
      "        ^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 112, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/.cache/torch/hub/facebookresearch_dino_main/vision_transformer.py\", line 60, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=33176, ip=192.168.1.105, actor_id=52e5c927b31cc6991cfd3ffe01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x78fab8bafc20>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml_flower/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.clientapp.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 32.62 MiB is free. Including non-PyTorch memory, this process has 1.92 GiB memory in use. Of the allocated memory 1.77 GiB is allocated by PyTorch, and 103.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)'>\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: Sampled 10 nodes (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Using cache found in /home/einrich99/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Loading iCaRL classifier from local cache: /home/einrich99/Progetti/FL-task-arithmetic/utilities/trained/nearest_centroid_classifier.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "run_config = \"conf1.toml\"\n",
    "\n",
    "command = f\"cd .. && flwr run --run-config config/{run_config}\"\n",
    "os.system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
