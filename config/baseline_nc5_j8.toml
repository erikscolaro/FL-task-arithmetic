# Baseline FedAvg configuration: N_c=5 (high non-IID), J=8 local epochs

# Federated learning parameters
num-server-rounds = 30
num-classes-per-partition = 5
local-epochs = 8
fraction-train = 0.1

# Disable sparse fine-tuning for baseline
use-sparse-finetuning = false

# Wandb configuration
group = "baseline-fedavg-nc5-j8"
notes = "Baseline FedAvg with N_c=5 classes per partition, J=8 local epochs, 100 nodes, 10% participation"
